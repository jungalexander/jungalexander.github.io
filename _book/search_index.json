[
["index.html", "EffectLiteR Tutorial - Work In Progress 1 Index", " EffectLiteR Tutorial - Work In Progress Alexander Jung, Christoph Kiefer &amp; Axel Mayer 1 Index EffectLiteR ist eine auf der Statistiksoftware R (und dem R-Paket lavaan) basierende Applikation, die zur Analyse bedingter und durchschnittlicher Treatment-Effekte vorgesehen ist. Unter bedingten Treatment-Effekten versteht man die Wirkung einer Treatment-Bedingung im Vergleich zu einer Kontroll-Bedingung und unter bestimmten Kovariaten-Ausprägungen. Eine Besonderheit von EffectLiteR ist dabei, dass es grundsätzlich bedingte und durchschnittliche Effekte schätzt, die sich im Falle unbalancierter Designs von Haupteffekten (wie sie etwa SPSS ausgibt) unterscheiden. EffectLiteR unterscheidet sich von den meisten anderen R-Paketen dadurch, dass es über eine eigene Benutzeroberfläche verfügt: Man kann (anstatt selbst R-Code zu schreiben) per Mausklick auf dieser Benutzeroberfläche Befehle spezifizieren, diese werden in R-Code übersetzt, in R berechnet und die Ergebnisse der Analysen werden in der Benutzeroberfläche darstellt. Das bedeutet: alles was EffectLiteR kann (und noch vieles mehr) ist auch mit R möglich, die Verwendung von EffectLiteR vereinfacht die Anwendung allerdings deutlich. Das vorliegende Tutorial führt schrittweise in das Denken in bedingten Effekten und die Verwendung der EffectLiteR-Oberfläche ein. Das erste inhaltliche Kapitel beschreibt, wie einfache Modelle, in denen eine abhängige Variable lediglich durch eine Treatment-Variable vorhergesagt wird, in einer einfachen linearen Regression parametrisiert und ausgewertet werden können. Im Kapitel zweifache lineare Regression werden die Modelle um eine zusätzliche Kovariate erweitert, im Kapitel bedingte lineare Regression wird schließlich auch der Effekt der Interaktion aus Treatment-Variable und Kovariate auf die abhängige Variable berücksichtigt. Sobald du das Grundprinzip der bedingten linearen Regression verstanden hast gibt es ein weiteres Kapitel, mit Übungen zur Interpretation immer komplexer werdender Modelle mit mehreren Kovariaten. Das Tutorial ist voller Screenshots, die zeigen wo, was eingegeben werden kann und voller praktischer Übungen, die meist an einem bereitgestellten simulierten Datensatz durchgeführt werden können. Zu allen praktischen Übungen gibt es Lösungsvideos. Die Idee hinter den Übungen und Lösungsvideos ist es, euch die Möglichkeit zu geben neben dem theoretischen Verständnis der Materie auch die „Mechanik“ der Applikation durch ausprobieren und durch Lernen am Modell zu verinnerlichen. Das nächste Kapitel startet direkt mit Screenshots und Videos zum Download der Applikation. In diesem Sinne: Viel Spaß und Erfolg beim Lesen, Üben und Erlernen der Software! "],
["installation.html", "2 Installation 2.1 Download und Verwendung via R 2.2 Download mit dem Windows-Installer", " 2 Installation Das (kostenfreie!) EffectLiteR kann auf zwei verschiedenen Wegen installiert und genutzt werden: Zum einen ist es möglich EffectLiteR über die Statistik-Software R zu verwenden, zum anderen ist es für Windows auch möglich EffectLiteR über einen Stand-Alone-Installer zu downloaden. Auch der Stand-Alone-Installer installiert im Hintergrund R. 2.1 Download und Verwendung via R R ist eine kostenfreie Open-Source-Statistiksoftware. Open Source bedeutet, dass verschiedene Wissenschaftler/Programmierer zusätzliche Pakete schreiben können, mit denen zusätzliche Rechenoperationen auf R ermöglicht werden. EffectLiteR ist ein solches zusätzliches Paket. Das Download läuft in drei Schritten ab. 2.1.1 Schritt 1 – R downloaden Die Installation von R ist in einigen Screenshots sowie in einem kurzen Video weiter unten dokumentiert. Unter dem Link https://cran.r-project.org/mirrors.html findest du verschiedene „Mirrors“ für R, das heißt du findest Links zum Download von R, die von verschiedenen Institutionen bereitgestellt werden. Es wird empfohlen den Link der geographisch am nächsten liegenden Institution zu verwenden. Klicke auf einen Mirror, Wähle das von dir verwendete Betriebssystem aus, dann downloade R. Figure 2.1: Download von R Nach Klick auf install R for the first time downloadet eine .exe-Datei, die ausgeführt werden muss um R zu installieren. Öffnest du die Datei wirst du durch einen Installer geführt. In den meisten Fällen empfiehlt es sich die 64-Bit-Version von R herunterzuladen und den Haken bei der 32-Bit-Version zu entfernen. Wenn du Schwierigkeiten bei der Installation von R hast, schaue dir folgendes Video an: 2.1.2 Schritt 2 – RStudio downloaden Mit R hast du das Programm heruntergeladen, das die Rechenoperationen im Hintergrund ausführt, R selbst hat aber keine benutzerfreundliche Oberfläche. Eine Oberfläche, mit der R bedient werden kann, ist RStudio. RStudio kann unter dem Link https://www.rstudio.com/products/rstudio/download/ heruntergeladen werden. Scrolle etwas herunter und wähle die RStudio-Desktop-Version aus (1), dann klicke auf den Download-Button der Version, die dir passend für dein Betriebssystem vorgeschlagen wird (2). Figure 2.2: Download von RStudio Durch den Klick auf Download RStudio downloadet eine weitere .exe-Datei, die zur Installation ausgeführt werden muss. Hierbei können alle Voreinstellungen übernommen werden. Download von RStudio im Video: 2.1.3 Schritt 3 – EffectLiteR installieren und öffnen Hast du RStudio installiert kannst du damit R bedienen und auf EffectLiteR zugreifen. EffectLiteR ist ein Packet, dass in R installiert, geladen und ausgeführt werden kann. Dafür öffne RStudio, klicke auf das kleine grüne Plus oben links und öffne durch Klick auf R Script ein neues R-Dokument, in das du Anweisungen schreiben kannst. Figure 2.3: Öffnen eines neuen R-Dokumentes Nun kannst du EffecLiteR installieren, indem du den Befehl install.packages(“EffectLiteR”) ausführst (siehe Figure 2.4). Achte darauf, dass die Schreibweise exakt der angegebenen Schreibweise entspricht (du kannst auch auf die Vorschläge klicken, die dir RStudio macht sobald du zu schreiben anfängst). Zum Ausführen des Befehls klicke auf Run, während sich der Cursor in der Zeile befindet, die du ausführen möchtest. Wenn du den Befehl korrekt ausgeführt hast, wird das Paket installiert, dies kann einige Zeit dauern. Die Installation ist abgeschlossen, sobald das kleine Stop-Symbol am oberen rechten Rand des unteren Fensters von RStudio verschwunden ist. Nachdem du das Paket installiert hast lade es, indem du den Befehl library(EffectLiteR) ausführst (auf korrekte Schreibweise achten, Cursor in die entsprechende Zeile, run klicken), danach öffne EffectLiteR durch ausführen von EffectLiteGUI(). Die beiden unteren Befehle (library(EffectLiteR) und EffectLiteGUI()) musst du zum Öffnen der Applikation jedes Mal neu ausführen. Speichere die Datei also um EffectLiteR in Zukunft schneller aufrufen zu können. Figure 2.4: EffectLiteR installieren und öffnen Installation und Öffnen von EffectLiteR im Video: 2.2 Download mit dem Windows-Installer Beachte: Nutze diese Funktion nicht, wenn du R bereits auf deinem PC installiert hast. Gelegentlich treten bei der Installation mit dem EffectLiteR-Standalone Installer Fehlermeldungen auf. Unter https://www.metheval.uni-jena.de/projekte/book_causal-effects/tools.php kann der EffectLiteR-Standalone-Installer heruntergeladen werden. Figure 2.5: Download EffectLiteR Stand-Alone-Installer Extrahiere den Zip-Compremierten Ordner und starte den msiinstaller/oder Setup?, folge den Anweisungen des Installers Figure 2.6: Installieren von EffectLiteR mit dem msiinstaller "],
["Einlesen-Schaltflächen.html", "3 Daten einlesen und Schaltflächen 3.1 Aufbau der graphischen Oberfläche 3.2 Daten einlesen 3.3 Übungsaufgabe “Dateneinlesen”", " 3 Daten einlesen und Schaltflächen 3.1 Aufbau der graphischen Oberfläche EffectLiteR hat zwei Panels mit verschiedenen Reitern. Das Input-Panel am linken Rand dient der Spezifikation der Daten und der statistischen Tests, das Output-Panel am oberen Rand erlaubt die Betrachtung verschiedener Outputs. Unter dem Output-Panel werden die gewählten Ergebnisse dann angezeigt. Figure 3.1: EffectLiteR Panels Dieses Kapitel widmet sich dem Input-Panel, die relevantesten Reiter des Output-Panels werden im Laufe des Tutorials nach und nach eingeführt, hier nur in Kürze für den besseren Überblick: Data zeigt die momentan eingelesenen Daten an. EffectLiteR zeigt das geschätzte Regressionsmodell sowie die Effektgrößenschätzer an. Syntax zeigt die lavaan-Syntax an, die im Hintergrund von R berechnet wird (lavvan ist ebenfalls ein R-Paket). Results gibt den originalen lavvan-Output aus. Conditional Effects I zeigt Effektgrößenschätzer für jede Person des Datensatzes an (geschätzt anhand der Kovariaten-Ausprägungen der einzelnen Personen). Conditional Effects II - IV erlauben die Schätzung von Effekten unter selbst spezifizierten Kovariaten-Ausprägungen (CE II wenn die Ausprägungen aller Kovariaten spezifiziert werden sollen, CE III wenn nur einige Kovariaten-Ausprägungen spezifiziert werden sollen, CE IV wenn nur eine einzige Kovariaten-Ausprägung spezifiziert werden soll). User-Specified Tests werden in diesem Tutorial aktuell nicht behandelt. Plot 1 - 4 zeigen einige informative, interaktive Graphiken zum Datensatz und den 3.2 Daten einlesen 3.2.1 Beispieldatensätze EffectLiteR hat verschiedene Beispieldatensätze integriert, an denen Funktionen des Programmes getestet werden können. Die Beispieldatensätze können im Input-Panel unter dem Reiter Data durch Klick auf choose example data ausgewählt und geladen werden. Ist ein Datensatz geladen beziehen sich auch alle durchgeführten Tests auf diesen Datensatz. Hast du in der aktuellen Sitzung bereits einen eigene Datensatz geladen kannst du zwar weitere eigene Datensätze, aber keine Beispieldatensätze mehr neu laden. Schließe die Anwendung hierfür und öffne Sie dann erneut. 3.2.2 Eigene Datensätze Ebenfalls unter dem Eingabe-Reiter Data gibt es die Möglichkeit unter Data File eigene Datensätze auszuwählen und zu laden. Folgende Dateitypen werden von EffectLiteR erkannt: .csv, .dat, .txt, .sav, .xpt und .rds. Excel-Files können (unter speichern unter) im .csv-Format gespeichert werden, das .sav-Format wird von SPSS verwendet. Beachte: Mit EffectLiteR können Datensätze ausgewertet, nicht aber bearbeitet werden. Es ist nicht möglich einzelne Datenpunkte zu ändern oder zu löschen, es ist nicht möglich existente Variablen zu löschen oder neue Variablen zu berechnen. Die Datenaufbereitung sollte also vor der Analyse mit EffectLiteR in einem anderen Programm, z.B. in R, erfolgen. Zum Laden eines eigenen Datensatzes durchsuche deinen Computer nach der gewünschten Datei durch einen Klick auf Browse. Wenn du eine Datei ausgewählt hast, sollte EffectLiteR die gewünschten Daten automatisch laden und anzeigen (sofern du im Output-Panel am oberen Rand den Reiter Data ausgewählt hast. Wenn die Daten gar nicht angezeigt werden hast du eventuell eine Datei mit einem nicht unterstütztem Dateiformat ausgewählt. Überprüfe, ob die Daten von EffectLiteR korrekt gelesen werden. Bei fehlerhafter Darstellung passe die Default-Einstellung unter Additional Options to Read Data an. 3.2.2.1 Änderungen der Default-Einstellungen Zum ändern der Default-Einstellungen scrolle im Input-Panel herunter bis du zu Additional Options to Read Data kommst (siehe Figure 3.2). Figure 3.2: Änderungen der Default-Einstellungen Die verschiedenen Einstellungsmöglichkeiten werden nun eine nach der anderen beschrieben. 3.2.2.1.1 Use value labels (SPSS Data) In SPSS können value labels definiert werden (bspw. „male“ für sex = 0 und „female“ für sex = 1). Unter Use value labels (SPSS Data) kann definiert werden, ob die value labels oder die Zahlencodes von EffectLiteR angezeigt werden sollen. Wenn du die Option yes oder default eingestellt hast, kann es vorkommen dass du bei der Berechnung bestimmter Regressionen im Hauptoutput Fehlermeldung wie die folgende erhältst: Figure 3.3: Fehlermeldung ‘unordered faktor(s): variable name’ Erhältst du eine solche Fehlermeldung ändere die Einstellung auf no und die Berechnung wird möglich. Du kannst zwischen den Einstellungen auch flexibel hin und her wechseln. 3.2.2.1.2 File contains Variable names (csv, dat and txt data) Hier gibst du an ob die erste Zeile deines Datensatzes Daten oder Variablennamen enthält. Wenn du hier yes auswählst werden die Zellen der erste Zeile des Datensatzes von EffectLiteR als Variablennamen übernommen. 3.2.2.1.3 Character seperating colums Hier gibst du an, wodurch die Spalten im Datensatz voneinander abgegrenzt werden. An den dargestellten Beispielen erkennst du, welche Einstellung (default, semicolon oder white space) du bei welcher Art der Spaltentrennung in deiner Daten-Datei wählen solltest. Figure 3.4: Character seperating colums 3.2.2.1.4 Decimal character Wähle aus, ob in deinen Dateien Kommas oder Punkte die Abgrenzung zwischen ganzen Zahlen und Nachkommastellen markieren. 3.2.2.1.5 Missing value code Hier kannst du, wenn nötig, einstellen, womit in deinem Datensatz fehlende Werte dargestellt werden. Falls beispielsweise „999“ für einen fehlenden Messwert steht, kannst du dies hier eingeben, damit EffectLiteR die Zahl als fehlenden Wert erkennt und ihn bei Berechnungen nicht als Zahlenwert mit einbezieht. Fehlende Werte, die das Programm als solche erkennt, werden von EffectLiteR grundsätzlich mit „NA“ dargestellt. 3.3 Übungsaufgabe “Dateneinlesen” Downloade den Übungsdatensatz 1 und lese ihn mit EffectLiteR ein. Der Datensatz entspricht nicht den Default-Einstellungen von EffectLiteR, du musst Änderungen an den Additional Options to Read Data vornehmen, insgesamt sind drei Änderungen notwendig, bevor du anfangen könntest Berechnungen am Datensatz vorzunehmen. Führe diese drei Änderungen durch, gehe Schrittweise vor und achte dabei auf Plausibilität der angezeigten Daten. Lösungen (mit Lösungsvideo) findest du hier. "],
["vorwort-zur-regressionsanalyse-mit-effectliter.html", "4 Vorwort zur Regressionsanalyse mit EffectLiteR", " 4 Vorwort zur Regressionsanalyse mit EffectLiteR EffectLiteR dient nicht primär der Analyse von Regressionsmodellen, sondern in erster Linie der Schätzung durchschnittlicher und bedingter Treatment Effekte basierend auf Regressionsmodellen. Dementsprechend lassen sich nicht alle Regressionsmodelle mit EffectLiteR berechnen sondern nur solche, die mindestens eine kategoriale Variable als Prädiktor enthalten. Diese kategoriale Prädiktor-Variable sollte eine Treatment-Bedingung darstellen, ihr Effekt wird im vorliegenden Tutorial konsequent als Treatment-Effekt bezeichnet. Die Kapitel-Aufteilung, die von der einfachen linearen Regression über die zweifache lineare Regression hin zur bedingten linearen Regression führt, dient der schrittweisen (vorlesungsbegleitenden) Heranführung an das Verständnis der Effektschätzung auf Basis des EffectLiteR-Ansatzes. Beachte: Zur inhaltlichen interpretation der Parameter der Regressionsmodelle werden im vorliegenden Tutorial viele Formeln verwendet. Was auf den ersten Blick kompliziert erscheint dient tatsächlich einer Vereinfachung des Verständnisses: Dadurch, dass jeder einzelne Rechenschritt in Formeln dargestellt wird, ist es möglich alle Formeln einfach nachzuvollziehen. Bitte tue das auch und lese nicht über die Formeln hinweg! "],
["eins.html", "5 Einfache lineare Regression 5.1 Input 5.2 Parametrisierung 5.3 Hauptoutput 5.4 Übungen “einfache lineare Regression”", " 5 Einfache lineare Regression 5.1 Input Die Einfache lineare Regression beschreibt den Zusammenhang einer unabhängigen Variablen (eines Prädiktors bzw. Regressors) mit einer kontinuierlichen abhängigen Variablen, dem Regressanden. Zur Berechnung einer einfachen linearen Regression in EffectLiteR muss lediglich definiert werden, welche Variable den Regressor und welche den Regressanden darstellen soll. Wähle dafür unter dem Reiter Manifest Variables im Input-Panel als Dependent Variable Y den Regressanden und als Treatment Variable X den Regressor aus. Figure 5.1: Einfache lineare Regression - Input Beachte: Als Treatment Variable X können nur kategoriale, aber keine kontinuierlichen Variablen ausgewählt werden (sonst erhältst du eine Fehlermeldung im Output-Screen), da das Programm zur analyse (kategorialer) Treatmenteffekte vorgesehen ist. 5.1.1 Referenzgruppe festlegen Per Default-Einstellung wird die am niedrigsten kodierte Gruppe (bei mit Worten kodierten Variablen wie grün, rot,… die nach alphabetischer Reihenfolge erste Gruppe) als Referenzgruppe verwendet. Um die Referenzgruppe zu ändern klicke im Input-Panel auf Options, dort kannst du die Referenzgruppe ändern (siehe Figure 5.2). Die inhaltlichen Auswirkungen eines Wechsels der Referenzgruppe werden später im Kapitel (hier) genauer beschrieben. Figure 5.2: Referenzgruppe - Input 5.2 Parametrisierung EffectLiteR schätzt eine Regressionsgleichung mit verschiedenen Parametern. Zu den einzelnen geschätzten Parametern gibt EffectLiteR Statistiken aus, beispielsweise zur Signifikanz der Parameter. Dementsprechend ist ein Verständnis der von EffectLiteR vorgenommenen Parametrisierung zum Verständnis des Hauptoutputs unabdingbar. Deshalb wird an dieser Stelle eine ausführliche Erläuterung dieser Parametrisierung vorgenommen. Zuerst am Beispiel einer zweistufigen Treatmentvariablen X, anschließend am Beispiel einer dreistufigen Treatmentvariablen X. 5.2.1 Zweistufige Treatmentvariable X EffectLiteR schätzt in diesem Fall folgendes Modell: \\[\\begin{align} E(Y|X) &amp;= g0() + g1() \\times I_{X=1}\\notag\\\\ g0() &amp;= g_{000}\\notag\\\\ g1() &amp;= g_{100} \\tag{5.1} \\end{align}\\] In der oberen Zeile der Gleichungen (5.1) sehen wir eine Gleichung, auf deren linker Seite ein Erwartungswert, \\(\\small E(Y|X)\\), und auf deren rechter Seite die beiden Funktionen, \\(\\small g0()\\) und \\(\\small g1()\\) stehen. Die \\(\\small g1()\\)-Funktion wird dabei mit einer sogenannten Indikatorvariable multipliziert, die entweder den Wert \\(0\\) oder den Wert \\(1\\) annimmt. Darunter finden wir eine Definition dieser Funktionen ($g0() = \\(g_{000}\\) und $g1() = \\(g_{100}\\)). \\(g_{000}\\) und \\(g_{100}\\) sind Parameter, die von EffectLiteR geschätzt und auf Signifikanz geprüft werden. Setzt man sie in die oberste Zeile ein erhält man Gleichung (5.2): \\[\\begin{align} E(Y|X) = g_{000} + g_{100} \\times I_{X=1} \\tag{5.2} \\end{align}\\] EffectLiteR schreibt die Regressionsgleichung in der obersten Zeile der Gleichungen (5.1) zunächst mit Funktionen und nicht direkt mit den Parametern, da die Terme der Funktionen bei komplexeren Regressionen mit mehreren Kovariaten immer länger werden. Stünden alle Parameter direkt in einer einzelnen Regressionsgleichung würde diese bei komplexeren Modellen sehr lang und unübersichtlich. EffectLiteR schätzt für uns den Wert der Parameter \\(g_{000}\\) und \\(g_{100}\\) und gibt beispielsweise an, ob die Parameter signifikant werden. Unser Ziel ist es also zu verstehen was die Parametern \\(g_{000}\\) und \\(g_{100}\\) inhaltlich bedeuten, um später interpretieren zu können was genau in unserer Analyse signifikant oder auch nicht signifikant wurde. Dafür gehen wir gemeinsam durch die einzelnen Komponenten der Gleichung (5.2). Um die inhaltliche Interpretation zu erleichtern führen wir vorher ein Beispiel ein. Beispiel 1 Ein Teil der Patienten einer Einrichtung erhält eine Behandlung, während ein anderer Teil keine Behandlung erhält. Es wird erhoben, wie es den Behandelten zu einem fixen Zeitpunkt einige Wochen nach Behandlungsbeginn gesundheitlich geht. Abhängige Variable Y : Gesundheitsscore von Patienten. Treatmentvariable X: Erhalten Patienten eine Behandlung (X=1) oder erhalten sie keine Behandlung (X=0). Auf der linken Seite der Gleichung (5.2) finden wir den Ausdruck \\(\\small E(Y|X)\\). \\(\\small E(Y|X)\\) gibt an, dass wir einen Erwartungswert berechnen, den Erwartungswert der Variable \\(\\small Y\\) in Abhängigkeit von \\(\\small X\\). Bezogen auf unser Beispiel: Wir berechnen den erwarteten Gesundheitsscore unter den verschiedenen Treatmentbedingungen. Der Erwartungswert unter der Bedingung \\(\\small X=0\\) (in Formelschreibweise: \\(\\small E(Y|X=0)\\)) kann vom Erwartungswert unter der Bedingung \\(\\small X=1\\) (\\(\\small E(Y|X=1)\\)) abweichen. In unserem Beispiel entspräche \\(\\small E(Y|X=0)\\) dem erwarteten Gesundheisscore von Patienten, die keine Behandlung erhalten, während \\(\\small E(Y|X=1)\\) dem erwarteten Gesundheisscore von Patienten entspricht, die eine Behandlung erhalten. Auf der rechten Seite von Gleichung (5.2) finden wir zwei Parameter, nämlich \\(g_{000}\\) und \\(g_{100}\\), sowie eine Indikatorvariable, nämlich \\(\\small I_{X=1}\\). Eine Indikatorvariable nimmt den Wert Eins an, wenn ihre Bedingung (in diesem Fall \\(\\small X=1\\)) erfüllt ist, in jedem anderen Fall nimmt sie den Wert Null an. Beachte Für den Fall, dass die Treatmentvarible nicht mit den Zahlen \\(\\small 0\\) und \\(\\small 1\\) kodiert ist (sondern etwa mit \\(\\small 1\\) und \\(\\small 2\\) oder mit \\(\\small KG\\) und \\(\\small EG\\)), wird den verschiedenen Ausprägungen der Treatmentvariable dennoch ein „Variablenlevel“ zugeordnet, dass bei Null startet und dann in ganzen Zahlen steigt. So wird \\(\\small KG\\) evtl. dem Variablenlevel \\(\\small 0\\) zugeordnet und \\(\\small EG\\) dem Variablenlevel \\(\\small 1\\). Diese Zuordnung eines Variablenlevels kann man als Umkodierung der Treatmentvariable verstehen. Unter Cell Counts im Hauptoutput kann nachgesehen werden, welcher Variablenausprägung welches Variablenlevel zugeordnet wird. 5.2.1.1 Parameter \\(g_{000}\\) Berechnen wir den Erwartungswert von einem Fall, in dem \\(X\\) den Wert Null annimmt, so errechnet sich der bedingte Erwartungswert von Y nach folgender Gleichung: \\[\\begin{align} E(Y|X=0) = g_{000} + $g_{100}$ \\times 0 \\tag{5.3} \\end{align}\\] Bemerke: Die Bedingung der Indikatorvariable \\(\\small I_{X=1}\\) ist nicht erfüllt, wir betrachten schließlich den Erwartungswert unter der Bedingung \\(\\small X=0\\), deshalb nimmt die Indikatorvariable den Wert Null an. Dies bedeutet: Unter der Bedingung \\(\\small X=0\\) ist der Parameter \\(g_{000}\\) gleich dem Erwartungswert von \\(\\small Y\\) unter der Bedingung \\(\\small X=0\\) bzw. \\(\\small E(Y|X=0) = g_{000}\\). EffectLiteR nutzt also den durchschnittlichen Wert der abhängigen Variable all jener Fälle, die der Bedingung \\(\\small X=0\\) entsprechen, um den Parameter \\(g_{000}\\) zu schätzen. In unserem Beispiel gäbe uns der Parameter \\(g_{000}\\) also den erwarteten \\(\\small Y\\)-Wert (Gesundheitsscore) für Patienten, die keine Behandlung erhielten. 5.2.1.2 Parameter \\(g_{100}\\) Berechnen wir den Erwartungswert von einem Fall in dem \\(\\small X\\) den Wert Eins annimmt, so errechnet sich der bedingte Erwartungswert von Y nach folgender Gleichung: \\[\\begin{align} E(Y|X=1) = g_{000} + $g_{100}$ \\times 1 \\tag{5.4} \\end{align}\\] Bemerke: Die Bedingung der Indikatorvariable \\(\\small I_{X=1}\\) ist erfüllt, deshalb nimmt sie den Wert eins an. In Gleichung (5.3) haben wir gezeigt, dass der Parameter \\(g_{000}\\) den Erwartungswert von \\(\\small Y\\) unter der Bedingung \\(\\small X=0\\), also \\(\\small E(Y|X=0)\\), darstellt. Setzen wir diesen Erwartungswert für \\(g_{000}\\) in die Regressionsgleichung oben (Gleichung (5.4)) ein, so können wir auch den Parameter \\(g_{100}\\) interpretieren. Es ergibt sich folgender Ausdruck: \\[\\begin{align} E(Y|X=1) &amp;= E(Y|X=0) + g_{100} \\times 1 \\notag\\\\ g_{100} &amp;= E(Y|X=1) - E(Y|X=0) \\tag{5.5} \\end{align}\\] Der Parameter \\(g_{100}\\) gibt den Unterschied zwischen dem Erwartungswert von \\(\\small Y\\) unter der Bedingung \\(\\small X=0\\) und dem Erwartungswert von \\(\\small Y\\) unter der Bedingung \\(\\small X=1\\) an (Gleichungen (5.5), untere Zeile). \\(g_{100}\\) gibt somit den geschätzten Effekt von \\(\\small X\\) auf \\(\\small Y\\) an: wird \\(\\small X\\) um eins größer, so wird der Erwartungswert von \\(\\small Y\\) um \\(g_{100}\\) größer. Wird der Parameter \\(g_{100}\\) signifikant heißt dies, dass es in der abhängigen Variable einen signifikanten Unterschied zwischen Fällen mit \\(\\small X=0\\) und \\(\\small X=1\\) gibt und dass es somit einen signifikanten Treatmenteffekt gibt. In unserem Beispiel gibt uns der Parameter \\(g_{100}\\) also die Erwartete Differenz zwischen dem Gesundheitsscore von Patienten die eine Behandlung erhielten und von Patienten, die keine Behandlung erhielten. Wird der Parameter \\(g_{100}\\) im EffectLite-Hauptoutput signifikant, bedeutet das in diesem Beispiel, dass die Behandlung einen signifikanten Effekt auf den Gesundheitsscore der Patienten hat. (Kausalität kann natürlich nur angenommen werden, wenn eine randomisierte Zuweisung von Patienten zu den Gruppen Behandlung / keine Behandlung vorgenommen wurde, ansonsten muss von einem korrelativen Zusammenhang gesprochen werden). Um zu erkennen in welche Richtung ein gegebenenfalls signifikanter Effekt geht (haben Patienten mit oder ohne Behandlung einen höheren Gesundheitsscore) betrachten wir das Vorzeichen des \\(g_{100}\\) Parameters. Verdeutlichen lässt sich dies an der (umgestellten) obersten Zeile der Gleichungen (5.5): \\[\\begin{align} E(Y|X=1)-g_{100} = E(Y|X=0) \\tag{5.6} \\end{align}\\] Wir sehen: \\(\\small E(Y|X=1)\\) ist um den Parameter \\(g_{100}\\) größer als \\(\\small E(Y|X=0)\\). Daraus schließen wir: Falls \\(g_{100}\\) positiv ist, gilt: \\(\\small E(Y|X=1) &gt; E(Y|X=0)\\). Es gibt einen positiven Treatment-Effekt. Falls \\(g_{100}\\) negativ ist, gilt: \\(\\small E(Y|X=1) &lt; E(Y|X=0)\\). Es gibt einen negativen Treatment-Effekt. 5.2.2 Dreistufige Treatmentvariable X Hat die Treatmentvariable \\(\\small X\\) eine Stufe mehr, so wird für diese Stufe eine weitere Funktion, \\(\\small g2()\\), multipliziert mit einer weiteren Indikatorvariablen, \\(\\small I_{X=2}\\), zum bisherigen Regressionsterm (Gleichung (5.2)) hinzuaddiert. Auch die \\(\\small g2()\\)-Funktion besteht nur aus einem Parameter. Folgendes Regressionsmodel wird von EffectLiteR geschätzt: \\[\\begin{align} E(Y|X) &amp;= g0() + g1() \\times I_{X=1} + g1() \\times I_{X=1}\\notag\\\\ g0() &amp;= g_{000}\\notag\\\\ g1() &amp;= g_{100}\\notag\\\\ g2() &amp;= g_{200} \\tag{5.7} \\end{align}\\] Auch hier wollen wir die drei Parameter \\(g_{000}\\), \\(g_{100}\\) und \\(g_{200}\\) wieder anhand eines Beispiels inhaltlich verstehen: Beispiel 2 Stellen wir uns vor, der Effekt zweier unterschiedlicher Behandlungen soll analysiert werden. Abhängige Variable \\(\\small Y\\): Gesundheitsscore von Patienten. Treatmentvariable \\(\\small X\\): Erhalten Patienten Behandlung Typ 1 (\\(\\small X=1\\)), erhalten sie Behandlung Typ 2 (\\(\\small X=2\\)) oder erhalten sie keine Behandlung (\\(\\small X=0\\)). Unser Vorgehen ist das selbe, wie im Beispiel 1 oben: Wir probieren die Parameter mit Erwartungswerten von \\(\\small Y\\) bzw. mit Differenzen zwischen Erwartungswerten von \\(\\small Y\\) auszudrücken. Dafür setzen wir zuerst die Parameter in das geschätzte Regressionsmodell ein: \\[\\begin{align} E(Y|X) &amp;= g_{000} + g_{100} \\times I_{X=1}+ g_{200} \\times I_{X=2} \\tag{5.8} \\end{align}\\] 5.2.2.1 Parameter \\(g_{000}\\) Unter der Bedingung \\(\\small X=0\\) nehmen beide Indikatorvariablen oben den Wert Null an und wir können den Parameter \\(g_{000}\\) interpretieren: \\[\\begin{align} E(Y|X=0) &amp;= g_{000} + g_{100} \\times 0 + g_{200} \\times 0 \\notag\\\\ E(Y|X=0) &amp;= g_{000} \\tag{5.9} \\end{align}\\] Bemerke: Weder die Bedingung der Indikatorvariable \\(\\small I_{X=1}\\), noch die Bedingung der Indikatorvariable \\(\\small I_{X=2}\\) sind gegeben. Deshalb nehmen beide Indikatorvariablen den Wert Null an. Der Parameter \\(g_{000}\\) stellt also den Erwartungswert von \\(\\small Y\\) unter der Bedingung \\(\\small X=0\\) dar. In unserem Beispiel: \\(g_{000}\\) schätzt den Gesundheitsscore von Patienten ohne Behandlung. 5.2.2.2 Parameter \\(g_{100}\\) Der Parameter \\(g_{100}\\) fällt in der Bedingung \\(\\small X=1\\) NICHT weg, betrachten wir also diesen Fall, um den Parameter \\(g_{100}\\) interpretieren zu können: \\[\\begin{align} E(Y|X=1) &amp;= g_{000} + g_{100} \\times I_{X=1} + g_{200} \\times I_{X=2} \\notag\\\\ &amp;= g_{000} + g_{100} \\times 1 + g_{200} \\times 0 \\tag{5.10} \\end{align}\\] Bemerke: Die Bedingung der Indikatorvariable \\(\\small I_{X=1}\\) ist gegeben, sie nimmt den Wert Eins an, die Bedingung der Indikatorvariable \\(\\small I_{X=2}\\) ist nicht gegeben, sie nimmt den Wert Null an. Wie bereits im Beispiel mit der zweistufigen Treatmentvariablen können wir den bedingten Erwartungswert \\(\\small E(Y|X=0)\\) für \\(g_{000}\\) einsetzen und somit dem Parameter \\(g_{100}\\) inhaltlichen interpretieren: \\[\\begin{align} E(Y|X=1) &amp;= E(Y|X=0) + g_{100} \\times 1 + g_{200} \\times 0 \\notag\\\\ g_{100} &amp;= E(Y|X=1) - E(Y|X=0) \\tag{5.11} \\end{align}\\] Der Parameter \\(g_{100}\\) gibt also wieder den Unterschied zwischen dem Erwartungswert von \\(\\small Y\\) unter der Bedingung \\(\\small X=0\\) und dem Erwartungswert von \\(\\small Y\\) unter der Bedingung \\(\\small X=1\\) an (untere Zeile). \\(g_{100}\\) gibt somit den geschätzten Effekt einer Veränderung von \\(\\small X=0\\) zu \\(\\small X=1\\) X auf die abhängige Variable \\(\\small Y\\) an: Ändert sich \\(\\small X\\) von null auf eins, so wird der Erwartungswert von \\(\\small Y\\) um \\(g_{100}\\) größer. In unserem Beispiel: \\(g_{100}\\) schätzt den Unterschied im Gesundheitsscore von Patienten die eine Behandlung erhielten und Patienten, die keine Behandlung erhielten. 5.2.2.3 Parameter \\(g_{200}\\) Der Parameter \\(g_{200}\\) bleibt nur unter der Bedingung \\(\\small X=2\\) erhalten. Wiederholen wir das gleiche Verfahren, das wir für den Parameter \\(g_{100}\\) angewandt haben, also für den Parameter \\(g_{200}\\), indem wir die Regressionsgleichung (Gleichung (5.8)) unter der Bedingung \\(\\small X=2\\) betrachten und \\(\\small E(Y|X=0)\\) für \\(g_{000}\\) einsetzen: \\[\\begin{align} E(Y|X=2) &amp;= g_{000} + g_{100} \\times I_{X=1} + g_{200} \\times I_{X=2} \\notag\\\\ &amp;= E(Y|X=0) + g_{100} \\times 0 + g_{200} \\times 1 \\notag\\\\ g_{200} &amp;= E(Y|X=2) - E(Y|X=0) \\tag{5.12} \\end{align}\\] \\(g_{200}\\) gibt somit den geschätzten Effekt einer Veränderung von \\(\\small X=0\\) zu \\(\\small X=2\\) auf die abhängige Variable \\(\\small Y\\) an: Ändert sich \\(\\small X\\) von null auf zwei, so wird der Erwartungswert von \\(\\small Y\\) um \\(g_{200}\\) größer. In unserem Beispiel: \\(g_{200}\\) schätzt die Differenz des Gesundheits-Scores von Patienten die keine Behandlung erhielten und Patienten die Behandlung 2 erhielten. In anderen Worten: \\(g_{200}\\) gibt den Effekt der Behandlungsmethode 2 auf den Gesundheitsscore an. Dem aufmerksamen Leser wird auffallen, dass bei dieser Art der Parametrisierung der Effekt einer Veränderung von \\(\\small X=1\\) zu \\(\\small X=2\\) (Der Unterschied im Gesundheits-Score von Patienten die mit Behandlungsmethode 1 und Patienten die mit Behandlungsmethode 2 behandelt wurden) nicht explizit geschätzt wird. Dieser Effekt kann betrachtet werden, indem die Referenzgruppe verändert wird. 5.2.3 Referenzgruppe Möchten wir die Differenz der Gruppen \\(\\small X=1\\) und \\(\\small X=2\\) kennen, können wir die Differenz aus \\(g_{200}\\) und \\(g_{100}\\) betrachten; dies würde uns über die Größe des Effektes eines Wechsels von \\(\\small X=1\\) und \\(\\small X=2\\) Auskunft geben. Die Differenz aus \\(g_{200}\\) und \\(g_{100}\\) wird allerdings bisher nicht als EffectLiteR-Parameter ausgegeben und nur für von EffectLiteR definierte Parameter erhalten wir Informationen zu Signifikanz und Standardfehler. Möchten wir die Signifikanz eines Untreschiedes zwischen den Treatmentbedingungen \\(\\small X=1\\) und \\(\\small X=2\\) interpretieren, müssen wir manuell die Referenzgruppe von EffectLiteR ändern. Wir müssen entweder die Gruppe \\(\\small X=1\\) oder die Gruppe \\(\\small X=2\\) als Referenzgruppe einstellen, damit diese Referenzgruppe dann mit den beiden anderen, nicht als Referenzgruppe eingestellten Gruppen verglichen wird. Auf diese Weise vergleichen wir die Gruppen \\(\\small X=1\\) und \\(\\small X=2\\) direkt miteinander. (Wie man die Referenzgruppe ändert lese hier). Ändern wir die Referenzgruppe ändert sich allerdings die Zuordnung der ursprünglichen Variablen-Kodierung zu den von EffectLiteR verwendeten Variablenleveln und damit auch die inhaltliche Interpretation aller Parameter! EffectLiteR weist uns darauf in seinem Hauptoutput unter Variables hin. In Figure 5.3 ist der Variables-Output für den Fall der ursprünglichen Referenzugruppe (“control” als Referenzgruppe) und für den Fall mit Behandlungsart 1 (“treat1”) als Referenzgruppe abgebildet. Figure 5.3: Wechsel der Referenzgruppe - Variables-Output Wenn vor dem Wechsel der Referenzgruppe also galt: \\(\\small g_{000} = E(Y|X=0=control)\\) \\(\\small g_{100} = E(Y|X=1=treat1) - E(Y|X=0=control)\\) \\(\\small g_{200} = E(Y|X=2=treat2) - E(Y|X=0=control)\\) So gilt nach dem Wechsel der Referenzgruppe: \\(\\small g_{000} = E(Y|X=0=treat1)\\) \\(\\small g_{100} = E(YIX=1=control) - E(Y|X=0=treat1)\\) \\(\\small g_{200} = E(YIX=2=treat2) - E(Y|X=0=treat1)\\) Bezogen auf unser Beispiel bedeutet dies: \\(g_{000}\\) schätzt nun den Erwartungswert der Gruppe mit Behandlungsart 1, die nun als Referenzgruppe fungiert. \\(g_{100}\\) schätzt noch immer den Unterschied zwischen Behandlungsart 1 und keiner Behandlung, aber das Vorzeichen ist herumgedreht. \\(g_{200}\\) schätzt nun den Unterschied zwischen der Gruppe mit Behandlungsart 1 und Behandlungsart 2. Es ist also bei der Interpretation des Outputs immer darauf zu achten, welche Treatmentgruppe als Referenzgruppe ausgewählt wurde! 5.3 Hauptoutput Den Hauptoutput findet man, wenn man im Output-Panel den Reiter EffectLiteR anklickt: Figure 5.4: Einfache lineare Regression - Hauptoutput Die verschiedenen Abschnitte des Hauptoutputs werden von oben nach unten einzeln beschrieben. 5.3.1 Message Wenn EffectLiteR die Regression berechnen konnte erhält man an dieser Stelle die Information: „model converged succesfully“, ansonsten erschein eine Fehlermeldung. 5.3.2 Variables Hier wird angezeigt, welche Variablen im Modell als Prädiktoren bzw. Regressoren berücksichtigt wurden. Außerdem ist ersichtlich welcher Variablenausprägung welches Variablenlevel zugeordnet wurde und welche Gruppe als Referenzgruppe ausgewählt wurde. Figure 5.5: Einfache lineare Regression - Hauptoutput In dem abgebildeten Screenshot kann abgelesen werden, dass: Die Kontrollgruppe, die Gruppe ist, die mit \\(\\small x=control\\) kodiert wurde, \\(\\small X=control\\) zu \\(\\small X=0\\) umkodiert wurde, \\(\\small X=treat1\\) zu \\(\\small X=1\\) umkodiert wurde und \\(\\small X=treat2\\) zu \\(\\small X=2\\) umkodiert wurde. Eine solche Umkodierung ist notwendig, weil die die Indikatorvariablen im Regressionsmodell auf den bei null beginnenden Variablenleveln beruhen. Das heißt es gibt keine Indikatorvariable \\(\\small I_{X=control}\\) sondern lediglich die Indikatorvariable \\(\\small I_{X=0}\\). 5.3.3 Regression Model Hier wird zuerst das (inhaltlich unter Parametrisierung beschriebene) Regressionsmodell angezeigt, darunter werden Informationen zu den empirisch geschätzten Parametern gegeben. Wir betrachten beispielhaft den Output einer einfaktoriellen Regressionsanalyse mit dreistufiger Treatmentvariable: Figure 5.6: Einfache lineare Regression - Hauptoutput Der Output unter dem Regressionsmodell ist dreigeteilt. Zuerst werden Informationen zur Intercept-Funktion \\(\\small g0()\\) angegeben: Der Intercept-Parameter \\(g_{000}\\), das heißt der Erwartungswert der abhängigen Variablen unter der Bedingung \\(\\small X=control\\) bzw. \\(\\small X=0\\) wird auf 0,018 geschätzt (siehe Kasten 1). Der Standardfehler dieses Schätzwertes liegt bei 0,037 (siehe Kasten 2). Die vierte Spalte (siehe Kasten 3) standardisiert die Parameter-Schätzer an ihrer geschätzten Standardabweichung (dem Standardfehler): Dies entspricht einer z-Standardisierung. Unterscheiden sich die Werte zweier Gruppen in dieser Spalte um mehr als \\(1,96\\) so unterscheiden sich die Gruppenmittelwerte auf einem \\(\\alpha\\)-Fehler-Niveau von \\(5%\\) bei zweiseitiger Testung signifikant voneinander. Da das Verhältnis von Schätzer zu Standardfehler kleiner als \\(1,96\\) ist, wird der Parameter \\(g_{000}\\) in einer „zweiseitigen“ Testung gegen Null nicht signifikant (Kasten 4): Wenn in Realität gar kein Effekt von dem Treatment \\(\\small X=1\\) ausgeht, liegt die Wahrscheinlichkeit, dass der Parameter \\(g_{000}\\) die Größe 0,018 oder größer, bzw. die Größe -0,018 oder kleiner gefunden wird, unter Annahme eines Standardfehlers von 0,037, bei 62,1%. Die Informationen zu den Effektfunktionen sind synonym zu lesen. Die Information [treat1 vs. control] (Kasten 5) gibt zusätzliche Auskunft zum Parameter \\(g_{100}\\): Hier wird angegeben, welche Bedingung gegen welche Bedingung getestet wird; die Bedingung „treat1“ wird gegen die Bedingung „control“ getestet. Welchen Kodierungen der Treatmentvariable „control“ und „treat1“ entsprechen, kann, wie bereits beschrieben, unter Variables nachgesehen werden. Die Bedingungen, die durch die Parameter der Effekt-Funktionen verglichen werden, verändern sich, wenn eine andere Referenzgruppe ausgewählt wird. 5.3.4 Cell Counts Unter Cell Counts kann nachgesehen werden, wie viele Beobachtungen pro Bedingung vorliegen: Figure 5.7: Einfache lineare Regression - Cell Counts Es liegen also im hier betrachteten Beispiel 686 Beobachtungen der Bedingung \\(\\small X=0\\), 615 Beobachtungen der Bedingung \\(\\small X=1\\) und 699 Beobachtungen der Bedingung \\(\\small X=2\\) vor. 5.3.5 Main Hypotheses Unter diesem Punkt werden verschiedene Hypothesen über mehrere Parameter getestet, die inhaltlich von Bedeutung sein könnten. Dafür wird der Wald-Test verwendet. Im Fall der einfachen linearen Regression wird nur eine Hypothese getestet, nämlich die Null-Hypothese, dass sich die Mittelwerte unter den verschiedenen Bedingungen der Treatmentvariable nicht signifikant unterscheiden, bzw. dass der Effekt der Stufen der Treatmentvariablen im Vergleich zur Referenzgruppe nicht signifikant von Null abweicht. Figure 5.8: Einfache lineare Regression - Main Hypotheses Der im Screenshot dargestellte Output stammt aus dem gleichen Bespiel, mit dreistufiger Treatmentvariable, wie die bisherigen Screenshots. Getestet wird die Overall-Hypothese, dass die Differenz zwischen \\(\\small EG1\\) (\\(\\small X=1\\)) und Referenzgruppe (\\(\\small X=0\\)) sowie die Differenz aus \\(\\small EG2\\) (\\(\\small X=2\\)) und Referenzgruppe jeweils nicht von Null verschieden sind. Der Test wird nicht signifikant, somit muss die Null-Hypothese nicht verworfen werden. Wir gehen davon aus (sofern die Power der Regression ausreichend groß ist), dass es auf Populationsebene keine Unterschiede zwischen den Bedingungen gibt. 5.3.6 Adjusted Means Unter diesem Punkt werden die Mittelwerte der abhängigen Variable unter den verschiedenen Bedingungen der Treatmentvaiablen und ihre Standardfehler angegeben. Unter Estimate wird der Mittelwert angzeigt, unter SE die Standardabweichung des Mittelwertes und unter Est./SE der Mittelwert standardisiert an seiner Streuung. Figure 5.9: Einfache lineare Regression - Adjusted Means Der Mittelwert der abhängigen Variablen unter der Bedingung \\(\\small X=0\\) beträgt also 0.01822. Die Standardabweichung des Mittelwerts beträgt 0.0368, damit ist der Mittelwert 0.495-mal so groß (das bedeutet er ist kleiner) wie seine Standardabweichung. Dass es sich bei den angegebenen Mittelwerte um adjustierte Mittelwerte handelt, gewinnt erst an Bedeutung, wenn weitere kategoriale Variablen in die Analyse mit einfließen, erst dann unterscheiden sich adjustierte Mittelwerte und Rand-Mittelwerte, wie sie etwa von SPSS geschätzt werden. Entsprechend wird das Konzept der adjustierten Mittelwerte auch erst bei der zweifachen und der bedingten linearen Regression detaillierter behandelt. 5.3.7 Average Effects Die durchschnittlichen Effekte beschreiben im Fall der einfachen linearen Regression den Unterschied der (adjustierten) Mittelwerte zwischen der Referenzgruppe und den beiden anderen Gruppen. In anderen Worten: die durchschnittlichen Effekte beschreiben in diesem Fall den Erwartungswert für die Parameter \\(g_{100}\\) und \\(g_{200}\\). Figure 5.10: Einfache lineare Regression - Hauptoutput Anmerkung: Die Effekte unter Average Effects entsprechen den Parametern \\(g_{100}\\) und \\(g_{200}\\) im Parameter-Output, sie sind lediglich weniger stark gerundet. Unter Estimate wird die Differenz zwischen den Mittelwerten angegeben, diese Differenz ist der Schätzer des (unstandardisierten) Effektes des Treatments 1: \\[\\begin{align} E[g1()] &amp;= Adj.Mean1 – Adj.Mean0 \\notag\\\\ &amp;= 0.00831 – 0.01822 \\notag\\\\ &amp;= -0.00991 \\tag{5.12} \\end{align}\\] Unter SE wird die Standardabweichung des Erwartungswertes angegeben, unter Est./SE der Quotient aus dem Erwartungswert und seiner Standardabweichung. Unter p-value wird angegeben, wie wahrscheinlich es ist einen Effekt dessen Betrag maximal so groß ist wie der Betrag des empirisch ermittelte Effekt zu finden, wenn auf Populationsebene kein Effekt vorliegt, es wird also ein „zweiseitig“ getestet. Unter Effekt Size wird der standardisierte Effekt angegeben. Dieser ergibt sich, wenn der unstandardisierte Effekt an der Standardabweichung der abhängigen Variable \\(\\small Y\\) in der Referenzgruppe standardisiert wird (d.h. wenn man den unstandardisierten Effekt durch diese Standardabweichung teilt). Die Standardabweichung der abhängigen Variable \\(\\small Y\\) in der Referenzgruppe können wir aus dem EffectLiteR Output nicht direkt ablesen. Der standardisierte Effekt kann wie Cohen‘s D oder Glass‘ Delta interpretiert werden. 5.4 Übungen “einfache lineare Regression” Der Übungsdatensatz 2 enthält (unter anderem) simulierte Daten für das Beispiel 2. Lese den Datensatz ein und wähle Gesundheitsscore als abhängige Variable und Behandlungsart als Treatmentvariable. 5.4.1 A) Interpretiere den Hauptoutput: Wie groß sind die jeweiligen Erwartungswerte des Gesundheitsscores unter den drei verschiedenen Behandlungsarten? Wie groß sind die deskriptiven Unterschiede zwischen den verschiedenen Bedingungen (keine Behandlung, Behandlung 1, Behandlung 2)? Unterscheiden sich alle drei Bedingungen signifikant von einander? Beachte: Um den Unterschied zwischen Behandlung 1 und Behandlung 2 zu interpretieren muss die Referenzgruppe verändert werden. 5.4.2 B) Errechne die Standardabweichung der abhängigen Variable Gesundheitsscore im Übungsdatensatz 2 für Personen, die keine Behandlung erhielten, mithilfe der Effektstärke aus dem EffectLiteR-Output. Wie das geht kannst du unter Average Effects nachlesen. Lösungen und ein Video zur Berechnung der ersten Aufgabe findest du hier. "],
["zwei.html", "6 Zweifache lineare Regression 6.1 Input 6.2 Parametrisierung 6.3 Hauptoutput 6.4 Übungen “zweifache lineare Regression”", " 6 Zweifache lineare Regression Die zweifache lineare Regression erlaubt es einen zweiten Regressor zur Vorhersage des Regressanden hinzuzuziehen, ohne jedoch eine mögliche Interaktion zwischen den Regressoren zu berücksichtigen beziehungsweise zu schätzen. Interaktionen werden gewöhnlich nur dann aus einem Messmodell ausgeschlossen, wenn es starke theoretische oder statistische Indizien dafür gibt, dass keine Interaktionen vorliegen. Im vorliegenden Tutorial wird die zweifache lineare Interaktion an diesem Punkt hauptsächlich aus didaktischen Gründen: In der zweifachen linearen Regression werden weniger Parameter geschätzt als in der bedingten lineare Regression, somit wird das Verständnis der bedingten linearen Regression schrittweise vorbereitet. 6.1 Input 6.1.1 Modell Die Default-Einstellung von EffectLiteR ist die bedingte lineare Regression, die nicht nur die Effekte der Regressoren auf den Regressanden, sondern zusätzlich noch den Einfluss der Interaktion zwischen den Regressoren auf den Regressanden schätzt. Möchte man solche Interaktionseffekt nicht schätzen, muss man dies einstellen. Das geht wie folgt: Im Input-Panel auf interactions klicken und no interactions auswählen. Figure 6.1: Modell-Definition als zweifache lineare Regression 6.1.2 Variablen Wie bei der einfachen linearen Regression ist es nötig unter dem Reiter Manifest Variables im Input-Panel eine abhängige Variable und eine (kategoriale) Treatmentvariable zu definieren. Zusätzlich muss der zweite Regressor als Kovariate definiert werden. Ist die Kovariate kategorial sollte sie durch Auswählen der Variable unter Categorical Covariates K als kategorial definiert werden, ist sie kontinuierlich, sollte sie unter Continous Covariates Z als kontinuierlich definiert werden. Figure 6.2: Definition der Kovariate der zweifachen linearen Regression 6.2 Parametrisierung Die Interpretation der Parameter der zweifachen linearen Regression unterscheidet sich dementsprechend, ob der zweite Regressor kontinuierlich oder kategorial ist. Wir gehen beide Fälle an jeweils einem Beispiel durch. 6.2.1 Parameter-Interpretation bei kategorialer Kovariate Zur modellierung der zweifachen linearen Regression werden im Fall einer zweistufigen Treatmentvariablen und einer ebenfalls zweistufigen kategorialen Kovariaten drei Parameter und zwei Indikatorvariablen genutzt: \\[\\begin{align} E(Y|X,K) = g_{000} + g_{010} \\times I_{K=1} + g_{100} \\times I_{X=1} \\tag{6.1} \\end{align}\\] Die Benennung der Parameter mit g000, g010 g100 entspricht der Benennung der Parameter durch EffectLiteR und wird am gegen Ende dieses Abschnitts erklärt. Wir drücken die Parameter wie bereits bei der einfachen linearen Regression mit Erwartungswerten aus, um ihre Bedeutung zu verstehen. Außerdem ergänzen wir unser bereits bekanntes Beispiel für die zweifache lineare Regression um eine weitere Variable: Beispiel 3 Abhängige Variable \\(\\small Y\\): Gesundheitsscore von Patienten. Treatmentvariable \\(\\small X\\): Erhalten Patienten eine (\\(\\small X=1\\)) oder erhalten sie keine (\\(\\small X=0\\)) Behandlung. Kovariate \\(\\small K\\): Patient gibt an in seinem Umfeld ausreichend soziale Unterstützung zu erhalten (\\(\\small K=1\\)) bzw. nicht genug Unterstützung zu erhalten (\\(\\small K=0\\)). Beachte: Wir gehen (in diesem Fall aus didaktischen Gründen) davon aus, dass es keine Interaktion zwischen Treatmentvariable \\(\\small X\\) und Kovariate \\(\\small K\\) gibt und verzichten deshalb darauf diese Interaktion zu modellieren. 6.2.1.1 Parameter g000 In der Modell-Gleichung (6.1) für dieses Beispiel gibt es drei Parameter und zwei Indikatorvariablen. Eine Indikatorvariable für die Treatmentvariable \\(\\small X\\) und eine für die kategoriale Kovariate \\(\\small K\\). Unter der Bedingung, dass sowohl \\(\\small X\\) als auch \\(\\small K\\) die Ausprägung Null annehmen, nehmen beide Indikatorvariablen ebenfalls den Wert Null an: \\[\\begin{align} E(Y|X=0,K=0) &amp;= g_{000} + g_{010} \\times I_{K=1} + g_{100} \\times I_{X=1}\\notag\\\\ &amp;= g_{000} + g_{010} \\times 0 + g_{100} \\times 0\\notag\\\\ g_{000}&amp;=E(Y|X=0,K=0) \\tag{6.2} \\end{align}\\] Der Parameter g000 schätzt also die Ausprägung des Regressanden unter der Bedingung \\(\\small X = 0\\) und \\(\\small K = 0\\). In unserem Beispiel 3 schätzt g000 den Gesundheitsscore von Patienten mit subjektiv zu geringer sozialer Unterstützung, die keine Behandlung erhalten. 6.2.1.2 Parameter g010 Um den Parameter g010 interpretieren zu können betrachten wir den Fall \\(\\small X = 0\\), \\(\\small K = 1\\). In diesem Fall wird nämlich der Parameter g100 mit Null multipliziert und wird somit irrelevant, während der Parameter g010 erhalten bleibt (Zeile 2 der Gleichungen (6.3)). \\[\\begin{align} E(Y|X=0,K=0) &amp;= g_{000} + g_{010} \\times I_{K=1} + g_{100} \\times I_{X=1} \\notag\\\\ &amp;= g_{000} + g_{010} \\times 1 + g_{100} \\times 0 \\notag\\\\ &amp;= E(Y|X=0,K=0) + g_{010} \\notag\\\\ g_{010} &amp;= E(Y|X=0,K=1) - E(Y|X=0,K=0) \\tag{6.3} \\end{align}\\] In Zeile drei der Gleichungen (6.3) wird der Erwartungswert \\(\\small E(Y|X=0,K=0)\\) für g000 (siehe Gleichungen (6.2)) eingesetzt, Zeile vier stellt die Gleichung nach g010 um. Der Parameter g010 schätzt somit die Differenz des Erwartungswertes von \\(Y\\) unter der Bedingung \\(\\small X = 0\\) und \\(\\small K = 0\\) und unter der Bedingung \\(\\small X = 0\\) und \\(\\small K = 1\\). Damit schätzt der Parameter g010 den Effekt, den eine Veränderung von \\(\\small K = 0\\) zu \\(\\small K = 1\\) auf \\(Y\\) ausübt. In unserem Beispiel schätzt g010 also den Effekt der subjektiven sozialen Unterstützung der Patienten auf ihren Gesundheitsscore. Wenn wir uns die letzte Zeile von Gleichung @ref\\tag{6.3} etwas genauer anschauen, sehen wir, dass die Erwartungswerte, die wir hier vergleichen, zwei Bedingungen haben: Die Gleichung vergleicht den Erwartungswert von \\(Y\\) gegeben \\(K=1\\) und \\(X=0\\) mit dem Erwartungswert von \\(Y\\) gegeben \\(K=0\\) und \\(X=0\\). Genau genommen müssten wir also sagen: g010 schätzt den Effekt, den eine Veränderung von \\(\\small K = 0\\) zu \\(\\small K = 1\\) unter der Bedingung \\(X=0\\) auf \\(Y\\) ausübt. Diesen kursiv geschriebenen Zusatz können wir bei der zweifachen linearen Regression allerdings weglassen: Per Definition gibt es hier keine Interaktion zwischen der Treatment-Variable \\(X\\) und der Kovariaten \\(K\\), das heißt der Effekt der Kovariaten ist unter der Bedingung \\(X=0\\) identisch mit dem unbedingten Effekt der Kovariaten. Bezogen auf unser Beispiel heiße das: Der Effekt der subjektiv berichteten sozialen Unterstützung, die Patienten erhalten, auf ihren Gesundheitsscore ist (per Definition) unabhängig davon, ob die Patienten eine Behandlung erhalten oder nicht. 6.2.1.3 Parameter g100 Betrachten wir den Fall \\(\\small X = 1\\) und \\(\\small K = 0\\) um Parameter g100 zu interpretieren. In diesem Fall wird der Parameter g010 mit Null multipliziert, während der Parameter g100 erhalten bleibt: \\[\\begin{align} E(Y|X=1,K=0) &amp;= g_{000} + g_{010} \\times I_{K=1} + g_{100} \\times I_{X=1} \\\\ &amp;= g_{000} + g_{010}\\times 0 + g_{100}\\times 1 \\notag\\\\ &amp;= E(Y|X=0,K=0) + g_{100} \\notag\\\\ g_{100} &amp;= E(Y|X=1,K=0) - E(Y|X=0,K=0) \\notag \\tag{6.4} \\end{align}\\] Das Vorgehen ist das selbe wie bei der Berechnung von Parameter g010. Der Parameter g100 schätzt also die Differenz in \\(\\small Y\\) zwischen der Bedingung \\(\\small X = 0\\) und \\(\\small K = 0\\) und der Bedingung \\(\\small X = 1\\), \\(\\small K = 0\\). Damit schätzt der Parameter den Treatmenteffekt, den eine Veränderung von \\(\\small X = 0\\) zu \\(\\small X = 1\\) auf \\(\\small Y\\) ausübt. Genau genommen haben wir hergeleitet, dass g010 den Treatmenteffekt von \\(\\small X\\) unter der Bedingung \\(\\small K = 0\\) beschreibt. Da die zweifache lineare Regression allerdings keine Interaktion zwischen \\(\\small K\\) und \\(\\small X\\) zulässt ist der Treatmenteffekt der Variablen \\(\\small X\\) unabhängig von der Ausprägung von \\(\\small K\\). Die Bedingung \\(\\small K = 0\\) kann in diesem Fall also weggelassen werden. In unserem Beispiel 3 schätzt g100 den Effekt einer Behandlung auf den Gesundheitsscore (unabhängig von der subjektiven sozialen Unterstützung der Patienten). 6.2.1.4 Die Benennung der Parameter Die erste der drei Ziffern der von EffectLiteR geschätzten Parameter-Indizes bezieht sich auf die Ausprägung der Treatmentvariablen \\(X\\), die zweite der drei Ziffern auf die Ausprägung der kategorialen Kovariaten \\(K\\) und die dritte der drei Ziffern auf die kontinuierliche Kovariate \\(Z\\) (Kontinuierliche Kovariaten wurden in diesem Tutorial bisher noch nicht eingeführt). Parameter g000 Bezieht sich also auf den Erwartungswert unter der Bedingung \\(\\small X=0,K=0\\), g010 beziffert den Effekt der Kovariaten \\(\\small K=1\\) unter der Bedingung \\(\\small X=0\\) und der Parameter g100 auf den Effekt der Ausprägung \\(\\small X=1\\) der Treatmentvariable. 6.2.1.5 Von EffectLiteR angezeigtes Regressionsmodell Rechnet man eine zweifache lineare Regression für eine zweistufige Treatment-Variable und eine ebenfalls zweistufige kategoriale Kovariate mit EffectLiteR, so erhält man Schätzungen für die drei bisher behandelten Parameter: g000, g010 und g100. Das Modell, dass EffectLiteR dem Nutzer anzeigt ist allerdings das „vollständige“ Modell der bedingten linearen Regression. Dies bedeutet, dass zusätzlich noch ein Parameter g110 angezeigt wird (in der bedingten linearen Regression würde dieser Parameter den Interaktionseffekt zwischen \\(\\small X\\) und \\(\\small K\\) schätzen). Da du für die zweifache lineare Regression allerdings unter Options festgelegt hast, dass es keine Interaktionen geben soll, wird der g110-Parameter von EffectLiteR auf Null festgelegt. Du kannst diesen Parameter bei der Interpretation also ignorieren. Dies soll im Folgenden verdeutlicht werden: Figure 6.3 bildet das von EffectLiteR im Hauptoutput angezeigte Regressionsmodell ab. Figure 6.3: Von EffectLiteR angezeigtes Regressionsmodell Durch Einsetzen der Parameter in die g0(K)- und g1(K)- Funktion erhält man Gleichung (6.5): \\[\\begin{align} E(Y|X,K) = (g_{000} + g_{010} \\times I_{K=1}) + (g_{100} + g_{110}\\times I_{K=1}) \\times I_{X=1} \\tag{6.5} \\end{align}\\] Da der „Interaktions-Parameter“ g110 bei der zweifachen linearen Regression auf Null fixiert wird, ergibt sich die bekannte Regressionsgleichung der zweifachen linearen Regression, deren Parameter wir soeben interpretiert haben: \\[\\begin{align} E(Y|X,K) &amp;= (g_{000} + g_{010} \\times I_{K=1}) + (g_{100} + 0\\times I_{K=1}) \\times I_{X=1}\\\\ &amp;= (g_{000} + g_{010} \\times I_{K=1}) + (g_{100}) \\times I_{X=1}\\notag \\end{align}\\] Im Parameteroutput wird der auf Null fixierte Parameter wie folgt angezeigt: Figure 6.4: Output des auf Null fixierten ‘Interaktionsparameters’ g110 6.2.2 Parameter-Interpretation bei kontinuierlicher Kovariate Das Regressionsmodell der zweifachen linearen Regression mit einer kontinuierlichen Kovariaten ähnelt dem Modell mit kategorialen Kovariaten stark. Hier einmal im Vergleich: kategoriale Kovariate kontinuierliche Kovariate \\(E(Y|X,K) = g_{000} + g_{010} \\times I_{K=1} + g_{100} \\times I_{X=1}\\) \\(E(Y|X,Z_1) = g_{000} + g_{001} \\times Z_1 + g_{100} \\times I_{X=1}\\) Der Unterschied zwischen beiden Regressionsgleichungen liegt darin, dass für eine kontinuierliche Kovariaten keine Indikatorvariable gebildet werden muss, sondern der Parameter g001 direkt mit der Ausprägung der Kovariaten multipliziert wird. Dass der Parameter für die Kovariate mit g001 statt g010 bezeichnet wird, trägt der Tatsache Rechnung, dass er sich auf den Effekt einer kontinuierlichen Kovariate bezieht (zur Benennung der Parameter lese hier). Kontinuierliche Kovariaten können so viele Werte annehmen, dass es nicht sinnvoll ist für jede empirisch gefundene Ausprägung eine eigene Indikatorvariable zu bilden. Um den Erwartungswert einer Person mit einer Kovariatenausprägung \\(\\small Z_1=z_1\\) gegeben \\(\\small X\\) zu errechnen, kann der Wert \\(\\small z_1\\) direkt für \\(\\small Z_1\\) in der oberen rechten Gleichung eingesetzt werden. Der Parameter g001 gibt für die kontinuierliche Kovariate also an, wie stark sich der Erwartungswert von \\(\\small Y\\) verändert, wenn die Kovariatenausprägung von \\(\\small Z_1\\) um eine Einheit steigt. Auch für den Fall einer kontinuierlichen Kovariaten möchten wie die Parameter durch Erwartungswerte ausdrücken, um sie inhaltlich zu verstehen. Zur besseren Veranschaulichung greifen wir auf folgendes Beispiel zurück: Beispiel 4 Nehmen wir an, wir erfassen, anders als in Beispiel 3 die Variable subjektive soziale Unterstützung statt als dichotome Variable (gegeben/nicht gegeben) als kontinuierliche Variable auf einer neun-stufigen Likert-Skala. Ansonsten nehmen wir keine Veränderungen gegenüber Beispiel 3 vor. Es ergeben sich folgende Variablen: Abhängige Variable Y: Gesundheitsscore von Patienten. Treatmentvariable X: Erhalten Patienten eine (\\(\\small X=1\\)) oder erhalten sie keine (\\(\\small X=0\\)) Behandlung. Kovariate \\(\\small Z_1\\): Beschreibt die wahrgenommene soziale Unterstützung auf einer Skala von 1-10. Beachte: Wir gehen noch immer (aus didaktischen Gründen) davon aus, dass es keine Interaktion zwischen Treatmentvariable X und Kovariate \\(\\small Z_1\\) gibt und verzichten deshalb darauf diese Interaktion zu modellieren. 6.2.2.1 Parameter g000 Um den Parameter g000 interpretieren zu können müssen die Parameter g010 und g100 aus der Modellgleichung rausfallen, d.h. sie müssen mit Null multipliziert werden. Der Parameter g010 fällt weg, wenn die Kovariate \\(\\small\\ Z_1\\) den Wert Null annimmt. In unserem Beispiel kann die Kovariate (gefühlte soziale Unterstützung) nicht direkt den Wert Null annehmen, da ihre Skala von 1-10 reicht. Es wäre also wünschenswert die Kovariate so zu Transformieren, dass sie einen Wert Null bekommt. Einschub: Transformation der Kovariaten Eine mögliche Transformation für die Kovariate aus unserem Beispiel wäre von jedem Skalenwert (\\(\\small 1-10\\)) jeweils eins abzuziehen, sodass die transformierte Skala von \\(\\small 0-9\\) reichen würde(\\(\\small Z_1 &#39;=Z_1-1\\)). Zur besseren Interpretierbarkeit des Einflusses der Kovariaten wird die Skala allerdings z-transformiert, das heißt die Skala der Kovariaten wird so transformiert, dass sie einen Mittelwert von \\(\\small \\bar{z_1} =0\\) und einer Standardabweichung von \\(\\small SD_{Z1}=1\\) erhält. Der Vorteil der z-Standardisierung ist der, dass der Parameter g010 nun den Einfluss einer Steigerung der Kovariaten um eine Standardabweichung angibt und nicht mehr den Einfluss der Steigerung um einen Skalenpunkt. Ein weiterer Vorteil liegt darin, dass die Parameter g000 und g100 durch diese z-Transformation der Kovariaten als durchschnittliche Effekte interpretierbar werden. Lese hierzu weiter im Text. Eine Variable kann mit folgender Formel z-standardisiert werden: \\(\\small X_{z-stand.}=\\frac{X-\\bar{x}}{SD_X}\\), wobei \\(\\small\\bar{x}\\) den Mittelwert der zu transformierenden Variable und \\(\\small SD_X\\) ihre Standardabweichung bezeichnet. Betrachten wir also den Erwartungswert von \\(Y\\) unter der Bedingung \\(\\small Z_1=\\bar{z}_1 =0\\) und \\(\\small X=0\\): \\[\\begin{align} E(Y|X=0,Z_1=\\bar{z}_1=0) &amp;= g_{000} + g_{001} \\times Z_1 + g_{100} \\times I_{X=0}\\notag\\\\ &amp;= g_{000} + g_{001} \\times 0 + g_{100} \\times 0\\notag\\\\ g_{000} &amp;= E(Y|X=0,Z_1= \\bar{z}_1=0) \\tag{6.6} \\end{align}\\] Der Parameter g000 schätzt bei einer z-standardisierten Skala also den von Z unabhängigen oder auch durchschnittlichen Erwartungswert von \\(\\small Y\\) (unter der Bedingung \\(\\small X=0\\), weil es bei der zweifachen linearen Regression keine Interaktionen zwischen Treatment-Variable und Kovariaten gibt kann diese Bedingung ignoriert werden). In unserem Beispiel schätzt g000 den erwarteten Gesundheitsscore von Personen mit einer durchschnittlichen Ausprägung der Kovariaten „gefühlte soziale Unterstützung“ (unter der Bedingung, dass keine Behandlung erfolgt). Damit schätzt der Parameter auch den Durchschnitt der Effekte von \\(\\small X=1\\), die für alle Personen der Stichprobe einzeln geschätzt werden. 6.2.2.2 Parameter g001 Um den Parameter g001 interpretieren zu können, muss der Parameter g100 aus der Modellgleichung rausfallen, d.h. mit Null multipliziert werden, während der Parameter g001 erhalten bleibt. Ist die Ausprägung der Kovariaten \\(\\small Z_1\\) genau eine Standardabweichung größer als ihr Mittelwert \\(\\small \\bar{z}\\) so nimmt sie aufgrund der z-Standardisierung den Wert \\(\\small 1\\) an. der Parameter g001 wird unter der Bedingung \\(\\small Z_1=\\bar{z}_1+SD_{Z1}=1\\) also mit Eins multipliziert, was seine Interpretation erleichtert. Der Parameter g100 wird unter der Bedingung \\(\\small X \\neq 1\\) (in unserem Beispiel \\(\\small X=0\\)) mit Null multipliziert. In Gleichungen ausgedrückt: \\[\\begin{align} E(Y|X=0,Z_1= \\bar{z}_1+SD_{Z1}=1) = g_{000} + g_{001} \\times 1 + g_{100} \\times 0 \\tag{6.7} \\end{align}\\] Durch Einsetzen von \\(\\small E(Y|X=0,Z_1= \\bar{z}_1 = 0)\\) für g000 in Gleichung (6.7) erhalten wir: \\[\\begin{align} E(Y|X=0,Z_1= \\bar{z}_1+ SD_{Z1}=1) = E(Y|X=0,Z_1= \\bar{z}_1=0) + g_{001}\\notag\\\\ g_{001} = E(Y|X=0,Z_1= \\bar{z}_1+ SD_{Z1}) - E(Y|X=0,Z_1= \\bar{z}_1) \\tag{6.8} \\end{align}\\] Dies Bedeutet: Der Parameter g001 schätzt die Differenz in \\(\\small Y\\) für Personen mit einer durchschnittlichen Kovariaten-Ausprägung und solchen mit einer um eine Standardabweichung größeren Kovariatenausprägung (unter der Bedingung \\(\\small X=0\\)). Die Bedingung \\(\\small X=0\\) hat, wie schon für das Beispiel mit der kategorialen Kovariaten erklärt, keine Bedeutung, weil in der zweifachen linearen Regression Interaktionen ausgeschlossen werden. In unserem Beispiel drückt der Parameter also die erwartete Differenz im Gesundheitsscore für Personen mit durchschnittlicher Ausprägung in der Kovariaten „gefühlter sozialer Unterstützung“ und solchen mit um eine Standardabweichung überdurchschnittlicher „gefühlter sozialer Unterstützung“ aus. 6.2.2.3 Parameter g100 Für die Interpretation des Parameters g100 betrachten wir den Erwartungswert von \\(\\small Y\\) unter der Bedingung \\(\\small X=1\\) (damit die Indikatorvariable \\(\\small I_{X=1}\\) den Wert Eins annimmt) und \\(\\small Z_1= \\bar{z}_1=0\\) (damit der Parameter g001 mit Null multipliziert wird): \\[\\begin{align} E(Y|X=1,Z_1= \\bar{z}_1=0) = g_{000} + g_{001} \\times 0 + g_{100} \\times 1 \\tag{6.9} \\end{align}\\] Durch Einsetzen von \\(\\small E(Y|X=0,Z_1=\\bar{z}_1=0)\\) für g000 in Gleichung (6.9) erhalten wir: \\[\\begin{align} E(Y|X=1,Z_1= \\bar{z}_1=0) &amp;= E(Y|X=0,Z_1=\\bar{z}_1=0) + g_{100}\\\\ g_{100} &amp;= E(Y|X=1,Z_1= \\bar{z}_1) - E(Y|X=0,Z_1=\\bar{z}_1) \\tag{6.10} \\end{align}\\] Der Parameter g100 schätzt also (wie auch bei der zweifachen linearen Regression mit kategorialer Kovariaten) die Abweichung zwischen der Ausprägung von \\(\\small Y\\) im Fall \\(\\small X=0\\) und im Fall \\(\\small X=1\\) (unter der Bedingung \\(\\small Z_1 = \\bar{z}_1=0\\), die in der zweifachen linearen Regression nicht beachtet werden muss, da keine Interaktionen zugelassen werden). Der Parameter g100 schätzt damit den Effekt den das Treatment (in unserem Beispiel eine Behandlung) auf die abhängige Variable (in unserem Beispiel den Gesundheitsscore) ausübt. 6.2.2.4 Von EffectLiteR angezeigtes Regressionsmodell Wie schon im Beispiel mit der kategorialen Kovariaten wird auch bei Verwendung einer kontinuierlichen Kovariaten das „vollständige Modell“ der bedingten linearen Regression mit einem auf Null fixierten Interaktionsparameter angezeigt, synonym wie oben beschrieben, kann hergeleitet werden, dass der auf Null fixierte Parameter keine Auswirkungen auf die Schätzung der anderen Parameter hat und im Output ignoriert werden kann. 6.3 Hauptoutput In der Beschreibung des Hauptoutputs der zweifachen linearen Regression wird an mehreren Stellen auf die Beschreibung des Hauptoutputs der einfachen linearen Regression verwiesen. Es ist von Vorteil sich zuerst mit dem Output der einfachen linearen Regression vertraut zu machen. 6.3.1 Variables Hier wird angezeigt, welche Variablen im Modell als Prädiktor bzw. Regressor berücksichtigt wurden. Außerdem wird wieder die Zuordnung der ursprünglichen Variablenkodierung zu den umkodierten Variablenlevels und der entsprechenden Indikatorvariable angezeigt. Auch hier wird dargestellt, welche Gruppe als Referenzgruppe verwendet wird. Figure 6.5: Variables-Output: Umkodierung der Treatmentvariablen In der Beispielgraphik oben kann abgelesen werden, dass die Kategorie „control“ mit \\(\\small 0\\) kodiert ist. Die Indikatorvariable \\(\\small I_{X=0}\\) nimmt also für Probanden der Kontrollgruppe den Wert Eins und für anderen Probanden den Wert Null an. Im Falle einer kategorialen Kovariaten wird eine vergleichbare Umkodierung auch für die Kovariate vorgenommen und ist ebenfalls unter Variables nachvollziehbar: Figure 6.6: Variables-Output: Umkodierung der kategorialen Kovariaten In diesem Beispiel kann also abgelesen werden, dass die Kategorie „male“ von EffectLiteR mit \\(\\small 0\\) kodiert wird. Die Indikatorvariable \\(\\small I_{K=0}\\) nimmt also für männliche Probanden den Wert Eins und für nicht männliche Probanden den Wert Null an. Ebenfalls nur bei kategorialen Kovariaten ist eine Bezeichnung verschiedener Zellen zu finden. Für jede Kombination der verschiedenen Ausprägungskombinationen aus Treatmentvariable und Kovariate wird eine Zelle gebildet und mit einer Zahl benannt. Unter Cells, weiter unten im Hauptoutput, kann dann die Anzahl an Beobachtungen pro Zelle nachgesehen werden, auch einige Plots beziehen sich auf einzelne Zellen. Figure 6.7: Anzahl an Beobachtungen pro Zelle unter Cells 6.3.2 Regression Model Im Output des Regressionsmodells und der Paramter gibt es keine größeren Unterschiede zum Output der einfachen linearen Regression, bis auf den Fakt, dass natürlich mehr Parameter geschätzt werden und dementsprechend auch für mehr Parameter Schätzwert, Standardfehler und p-Wert angegeben werden. Wie bereits im Abschnitt Von EffectLiteR angezeigtes Regressionsmodell beschreiben, wird auch ein oder mehrer auf Null fixierter Interaktions-Parameter angezeigt, die bei der Interpretation ignoriert werden können: Figure 6.8: Variables-Output: Output mit einem auf Null fixierten Interaktions-Parameter 6.3.3 Cell Counts Im Falle einer kategorialen Kovariaten wird eine Tabelle mit Beobachtungen in einer Kombination aller möglichen Variablenausprägungskombinationen angezeigt, im Falle einer kontinuierlichen Kovariaten werden nur die Beobachtungen für die Ausprägungen der Treatmentvariable gezählt: Figure 6.9: Cell Counts: Output bei kontinuierlicher und kategorialer Kovariate Der Output (bei kategorialer Kovariate) ist wie folgt zu lesen: Es wurden 333 Fälle mit der Ausprägung \\(\\small X= 0\\) und \\(\\small K=0\\) beobachtet. Unter Variables-Cells kann nachgelesen werden, wofür diese Ausprägungen stehen: Es wurden 333 Männer unter der Bedingung „control“ beobachtet. 6.3.4 Main Hypotheses Betrachten wir mehr als nur einen Prädiktor, gibt es auch mehr Möglichkeiten Hypothesen über mehrere Parameter zugleich zu testen. Dabei gilt: Die Tests im Bereich Main Hypotheses können ohne Bedenken bezüglich etwaiger \\(\\alpha\\)-Fehler-Kumulierung interpretiert werden. Im Fall der zweifachen linearen Regression lassen sich die Hypothesen 1,2 und 4 interpretieren. Die dritte Hypothese, die sich auf Interaktionen bezieht, gewinnt erst bei der bedingten linearen Regression Bedeutung. Figure 6.10: Haupthypothesen-Tests 6.3.4.1 Hypothesentest 1 Getestet wird die Nullhypothese, dass die Erwartungswerte für alle Effektfunktionen gleich Null sind. Im Screenshot hat die Treatment-Variable drei Ausprägungen, dementsprechend gibt es zwei Effektfunktionen [\\(\\small g1(K)\\) und \\(\\small g2(K)\\)]. Die Nullhypothese besagt, dass die Effekte beider Effektfunktionen für alle Fälle des Beispiels im Durchschnitt den Wert Null annehmen bzw. dass weder das mit Eins noch das mit Zwei kodierte Treatment einen Effekt über das mit Null kodierte Treatment hinaus haben. Dies könnte auch wie folgt ausgedrückt werden: \\(\\small E[g0(K)] = E[g1(K)] = E[g2(K)]\\). In dieser Schreibweise ist leichter nachvollziehbar, woraus sich die Anzahl der Freiheitsgrade (\\(\\small df=2\\)) ergibt: Die Freiheitsgerade errechnen sich durch die Anzahl miteinander verglichener Gruppen minus \\(\\small 1\\). Wird der Test signifikant (\\(\\small p &lt; 0.05\\)) muss die Hypothese verworfen werden und man kann davon ausgehen, dass durchschnittliche Effekt des Treatments vorhanden sind, wird der Test nicht signifikant kann die Nullhypothese angenommen werden (unter der Annahme, dass die Power der getesteten Regressions-Analyse ausreichend groß ist). Bemerke: Dass die Effektfunktionen im Durchschnitt den Wert Null annehmen, bedeutet im Fall der zweifachen linearen Regression, dass es keine Treatment-Effekte gibt. Für die zweifache lineare Regression gibt es dementsprechend keine Unterschiede zwischen Hypothesentest 1 und Hypothesentest 4. Eine Unterscheidung zwischen diesen beiden Hypothesentests macht erst dann Sinn, wenn Interaktionen zwischen Treatment und Kovariaten geschätzt werden (wie in der bedingten linearen Regression). Dann kann es nämlich vorkommen, dass ein Treatment zwar unter bestimmten Bedingungen einen Effekt hat (getestet von Hypothese 4), im Durchschnitt aber keinen Effekt hat (Hypothesentest 1). Bei der zweifachen linearen Regression gibt es keine Interaktionen, somit ist der Effekt des Treatments unter allen Bedingungen von K identisch und der durchschnittliche Effekt gleicht den bedingten Effekten. 6.3.4.2 Hypothesentest 2 Getestet wird hier, ob es in der Kontrollgruppe Einflüsse der Kovariaten gibt. Da es bei der zweifachen linearen Regression keine Interaktionen zwischen Tretment-Variable und Kovariate gibt, testet dieser Test defacto ob die Kovariate überhaupt Einflüsse auf die abhängige Variable hat (wenn die Kovariate in der Kontrollgruppe keinen Einfluss auf die abhängige Variable hat und es keine Interaktionen gibt, dann hat die Kovariate auch in allen anderen Bedingungen keinen Einfluss auf die abhängige Variable). Hat die Kovariate keinen Einfluss auf die abhängige Variable (dies entspräche der getesteten Nullhypothese) so ist der Erwartungswert der Referenzgruppe unter allen Bedingungen von K identisch. Für den im Screenshot oben (Figure 6.10) abgebildeten Fall mit zwei Kovariaten-Ausprägungen ließe sich die Nullhypothese in der Kontrollgruppe (\\(\\small X=0\\)) formal wie folgt aufschreiben: \\(\\small E(Y|X=0,K=0) = E(Y|X=0,K=1)\\). Da der Einfluss von K auf den Erwartungswert von Y unter allen Bedingungen von X jedoch gleich ist, wenn keine Interaktionen vorliegen, kann in der zweifachen linearen Regression verallgemeinert werden: \\(\\small E(Y|X,K=0) = E(Y|X,K=1)\\). Da zwei Gruppen miteinander verglichen werden (die Gruppe mit der Ausprägung \\(\\small K = 0\\) und die mit der Ausprägung \\(\\small K=1\\)) haben wir (\\(\\small 2-1=1\\)) einen Freiheitsgrad. Alternativ könnte man die Gleichung auch wie folgt ausdrücken: \\(\\small g_{010} = 0\\). Der Parameter g010 drückt den Effekt der Kovariaten aus. Im Fall des Screenshots (siehe Abbildung oben) wird der Hypothesentest signifikant, das heißt die Nullhypothese kann verworfen werden: Mit einer Wahrscheinlichkeit von 98,96% (1 minus p-value) verändert sich der der Wert der abhängigen Variable auf Populationsebene in Abhängigkeit der Ausprägung der Kovariaten. 6.3.4.3 Hypothesentest 3 Da es bei der zweifachen linearen Regression keine Interaktionen zwischen Treatment und Kovariate gibt, kann der Test über Interaktionsparameter nicht berechnet werden. 6.3.4.4 Hypothesentest 4 Wie bereits unter Hypothesentest 1 beschrieben unterscheidet sich der Hypothesentest 4 bei der zweifachen linearen Regression nicht von Hypothesentest 1. 6.3.5 Adjusted Means Wie bei der einfachen linearen Regression werden Mittelwerte für die Ausprägung der abhängigen Y-Variablen unter verschiedenen Bedingungen von \\(\\small X\\) angezeigt. Die adjustierten Mittelwerte lassen sich im Fall der zweifaktoriellen Regression genauso interpretieren, wie im Fall der einfachen linearen Regression, da über die verschiednen Kovariaten-Ausprägungen gemittelt wird. Dass es sich um adjustierte Mittelwerte handelt bedeutet, dass bedingte Erwartungswerte (zum Beispiel der Erwartungswert von \\(\\small X=0\\) unter der Bedingung \\(\\small K=0\\)) für alle Zellen (siehe Variables – Cells) gebildet werden und dann entsprechend der proportionalen Häufigkeit der Ausprägungen der Kovariaten im Datensatz gewichtet werden. Da es bei der zweifachen linearen Regression per Definition keine Interaktion zwischen Kovariate und Treatmentvariable gibt, gibt es keine Unterschiede zwischen den verschiedenen bedingten Erwartungswerten und es tritt kein Effekt der Adjustierung zu Tage. Eine tiefergehende Erklärung zu adjustierten Mittelwerten findet sich im Exkurs adjustierte Mittelwerte. 6.3.6 Average Effects Die durchschnittlichen Effekte lassen sich im Fall der zweifaktoriellen Regression genauso interpretieren, wie im Fall der einfaktoriellen Regression, da über den zweiten Faktor, die Kovariate, gemittelt wird: Es werden die (durchschnittlichen) Effekte der Treatmentvarible geschätzt. EffectLiteR nutzt adjustierte Mittelwerte (adjusted means) um Effekte zu berechnen, viele andere Programme (u. a. SPSS) nutzen ungewichtete bedingte Randmittelwerte (marginal means) um Effekte zu berechnen. In unbalancierten Designs können die adjustierten Mittelwerte von den bedingte Randmittelwerten abweichen und sich somit auch die gefundenen Effekte zwischen EffectLiteR (durchschnittliche Effekte) und SPSS (Haupteffekte) unterscheiden. Dies ist ein Vorteil von EffectLiteR gegenüber SPSS. Siehe hierzu auch den Exkurs Adjustierte Mittelwerte. Durch das hinzufügen varianzaufklärender Kovariaten wird generell die Genauigkeit der Effektschätzung verbessert, das heißt der Standardfehler wird geringer. 6.3.7 Effects given a Treatment Condition Bei der zweifachen linearen Regression weichen die hier angezeigten Effekte nicht von den durchschnittlichen Effekten ab. Eine Erklärung des statistischen Konstruktes findet im Rahmen der bedingten linearen Regression statt. 6.3.8 Hypotheses given K=k (nur bei einer kategorialen Kovariaten): Hier wird der durchschnittliche Effekt von \\(\\small X\\) auf \\(\\small Y\\) unter den verschiedenen Bedingungen von \\(\\small K\\) getestet. Da die zweifache lineare Regression keine Interaktionen zwischen \\(\\small K\\) und \\(\\small X\\) zulässt, ist der durchschnittliche Effekt von \\(\\small X\\) unter allen Bedingungen von \\(\\small K\\) identisch und somit auch mit dem unbedingten durchschnittlichen Effekt identisch, der durch den Haupthypothesentest 1 getestet wird. Für die zweifache lineare Regression gibt es also keine Unterschiede zwischen den bedingten durchschnittlichen Effekten, die unter Hypotheses given K=k getestet werden und dem Hypothesentest 1 der unter Main Hypotheses getestet wird. 6.4 Übungen “zweifache lineare Regression” 6.4.1 A) Der Übungsdatensatz 2 enthält (unteranderem) simulierte Daten für das Beispiel 3 (allerdings mit drei statt zwei Treatment-Bedingungen). Lese den Datensatz ein, wähle Gesundheitsscore als abhängige Variable, Behandlungsart als Treatmentvariable und subjektiv ausreichend soziale Unterstützung als kategoriale Kovariate. Interpretiere den Hauptoutput: Wie groß ist der Erwartete Gesundheitsscore unter folgenden Bedingungen: Behandlungsart = 0, subj_ausreichend_soz_Unterstützung = 0 Behandlungsart = 0, subj_ausreichend_soz_Unterstützung = 1 Behandlungsart = 1, subj_ausreichend_soz_Unterstützung = 0 Behandlungsart = 1, subj_ausreichend_soz_Unterstützung = 1 Behandlungsart = 2, subj_ausreichend_soz_Unterstützung = 0 Behandlungsart = 2, subj_ausreichend_soz_Unterstützung = 1 Wie groß ist der Effekt von Behandlungsart 1 im Vergleich zu Behandlungsart 0 und ist er signifikant? Wie groß ist der Effekt von Behandlungsart 2 im Vergleich zu Behandlungsart 0 und ist er signifikant? Wie groß ist der Effekt von subjektiv ausreichender sozialer Unterstützung und ist er signifikant? 6.4.2 B) Nutze nun subjektive soziale Unterstützung als kontinuierliche Kovariate (entferne die kategoriale Kovariate), ansonsten belasse alle Variablen wie in Teil A) der Übung. Die verwendeten Variablen entsprechen nun Beispiel 4. Berechne eine zweifache lineare Regression von Behandlungsart und subjektiv gemessener sozialer Unterstützung (kontinuierlich) auf den Gesundheitsscore. Beachte: Zur Lösung der Aufgabe ist es hilfreich, wenn die kontinuierliche Kovariate z-standardisiert ist. Die z-Standardisierung muss vor dem Einlesen in EffectLiteR erfolgen. Interpretiere den Hauptoutput: Wie groß ist der erwartete Gesundheitsscore unter den verschiedenen Ausprägungen von X a) bei durchschnittlicher Ausprägung der Kovariate und b) bei einer Kovariaten-Ausprägung von einer Standardabweichung über dem Durchschnitt. Wie groß ist der Effekt von Behandlungsart 1 im Vergleich zu Behandlungsart 0 und ist er signifikant? Wie groß ist der Effekt von Behandlungsart 2 im Vergleich zu Behandlungsart 0 und ist er signifikant? Hat subjektive soziale Unterstützung einen signifikanten Einfluss auf den Gesundheitsscore? Welchen Effekt hat die Steigerung von subjektiver sozialer Unterstützung um anderthalb Standardabweichung auf den Gesundheitsscore? Lösungen und Videos zur Berechnung der Aufgaben sowie zur z-Standardisierung von Variablen findest du hier. "],
["bedingt.html", "7 Bedingte lineare Regression 7.1 Input 7.2 Parametrisierung 7.3 Hauptoutput 7.4 Übungen “bedingte lineare Regression”", " 7 Bedingte lineare Regression 7.1 Input Wird EffectLiteR geöffnet, ein Datensatz eingelesen und unter Manifest Variables im Eingabe-Panel eine abhängige Variable, eine kategoriale Treatmentvarible sowie eine oder mehrere kategoriale oder kontinuierliche Kovariate(n) definiert (ausführliche Beschreibung zum Input siehe Input der einfachen linearen Regression), so schätzt EffectLiteR ein bedingtes lineares Regressionsmodell. Die bedingte lineare Regression ist die Defaulteinstellung von EffectLiteR. Sollten zuvor unter dem Reiter Interactions im Eingabe-Panel Änderungen vorgenommen worden sein, um beispielsweise eine zweifache lineare Regression zu schätzen, so kann die bedingte lineare Regression durch ein Klick auf Full model wieder hergestellt werden. 7.2 Parametrisierung Anders als die zweifache lineare Regression lässt die bedingte lineare Regression eine Interaktion zwischen Treatmenteffekt und Kovariaten zu. Dies bedeutet, dass für jede geschätzte Interaktion (abhängig von der Anzahl der Stufen der Treatmentvariablen X, der Anzahl an Kovariaten, und der Anzahl an Stufen von kategorialen Kovariaten) ein weiterer Parameter in das Regressionsmodell aufgenommen wird. Auch für die bedingte lineare Regression betrachten wir einfache Beispiele mit einer kategorialen bzw. einer kontinuierlichen Kovariaten. 7.2.1 Zweistufige Kovariate, zweistufige Treatmentvariable Wir verwenden zur Veranschaulichung das gleiche Beispiel, dass wir schon bei der zweifachen linearen Regression verwendet haben, nur lassen wir jetzt die Annahme außen vor, dass es keine Interaktion zwischen Treatment-Variable und Kovariate gibt: Beispiel 5 Abhängige Variable \\(\\small Y\\): Gesundheitsscore von Patienten. Treatmentvariable \\(\\small X\\): Erhalten Patienten eine (\\(\\small X=1\\)) oder erhalten sie keine Behandlung (\\(\\small X=0\\)). Kovariate \\(\\small K\\): Patient gibt an in seinem Umfeld ausreichend soziale Unterstützung zu erhalten (\\(\\small K=1\\)) bzw. nicht genug Unterstützung zu erhalten (\\(\\small K=0\\)). Es liegen keine Informationen zu Interaktionen zwischen Treatmentvariable und Kovariate vor. EffectLiteR schätzt folgendes Modell: Figure 7.1: Regressionsmodell mit zweistufiger Treatmentvariable und zweistufiger Kovariate 7.2.1.1 Parameter g000, g010 und g100 Die Parameter g000, g010 und g100 können simultan durch Erwartungswerte ausgedrückt werden, wie bei der zweifachen linearen Regression mit zweistufiger Treatmentvariablen und zweistufiger kategorialen Kovariaten. Anders als bei der zweifachen linearen Regression müssen hier die Bedingungen von \\(\\small X\\) und von \\(\\small K\\), unter denen ein Effekt geschätzt wird, beachtet werden. 7.2.1.1.1 g000 \\[\\begin{align} g_{000} = E(Y|X=0, K=0) \\tag{7.1} \\end{align}\\] Der Parameter g000 schätzt die Ausprägung des Regressanden unter der Bedingung \\(\\small X=0\\) und \\(\\small K=0\\), siehe Gleichung (6.2). 7.2.1.1.2 g010 \\[\\begin{align} g_{010} = E(Y|X=0,K=1) - E(Y|X=0,K=0) \\tag{7.2} \\end{align}\\] Der Parameter g010 schätzt den Effekt der Kovariaten, den eine Veränderung von \\(\\small K=0\\) zu \\(\\small K=1\\) unter der Bedingung \\(\\small X=0\\) auf \\(\\small Y\\) ausübt, siehe Gleichung (6.3). Anders als bei der linearen zweifachen Interaktion ist die Bedingung \\(\\small X=0\\) hier von Bedeutung: Da Eine Interaktion zwischen \\(\\small X\\) und \\(\\small K\\) nicht ausgeschlossen wird, ist der Effekt der Kovariaten \\(\\small K\\) auf \\(\\small Y\\) unter einer anderen Ausprägung der Treatmentvariablen X gegebenenfalls ein anderer. 7.2.1.1.3 g100 \\[\\begin{align} g_{100} = E(Y|X=1,K=0) - E(Y|X=0,K=0) \\tag{7.3} \\end{align}\\] Der Parameter g100 schätzt den Treatmenteffekt, den eine Veränderung von \\(\\small X=0\\) zu \\(\\small X=1\\) unter der Bedingung \\(\\small K=0\\) auf \\(\\small Y\\) ausübt, siehe Gleichung (6.4). Beachte auch hier, dass die Bedingung \\(\\small K=0\\), anders als bei der zweifachen linearen Regression, von Bedeutung ist. 7.2.1.2 Parameter g110 Um den Parameter g110 inhaltlich zu verstehen, leiten wir in einem ersten Schritt her, wie der Parameter durch Erwartungswerte ausgedrückt werden kann. In einem zweiten Schritt wird am inhaltlichen Beispiel 5 verdeutlicht, dass der Parameter g110 nichts anderes darstellt, als einen Schätzer für die Interaktion zwischen Treatment und Kovariate. 7.2.1.2.1 Parameter g110 mit Erwartungswerten ausdrücken Der Parameter g110 ist Teil der Effektfunktion \\(\\small g1(k)\\), außerdem wird er mit der Indikatorvariable \\(I_{K=1}\\) multipliziert (siehe Gleichung (7.4): Modellgleichung der bedingten linearen Regression mit zweistufiger Kovariaten und zweistufiger Treatmentvariablen). \\[\\begin{align} E(Y|X,K) &amp;= g0(K)+g1(K)\\times I_{X=1} \\\\ &amp;=g_{000} + g_{010} \\times I_{K=1} + (g_{100} + g_{110} \\times I_{K=1}) \\times I_{X=1} \\tag{7.4} \\end{align}\\] Unter der Bedingung \\(X=0\\) wird die Effektfunktion mit Null multipliziert, under der Bedingung \\(K=0\\) wird der Parameter g110 mit Null multipliziert, das bedeutet die einzige Bedingung, unter der der Parameter g110 nicht mit Null multipliziert wird, ist die Bedingung \\(\\small X=1\\) und \\(\\small K=1\\). Betrachten wir die Bedingung \\(\\small X=1\\) und \\(\\small K=1\\) und setzen für alle drei bisher hergeleiteten Parameter g000, g010 und g100 ihre Erwartungswerte (bzw. Differenzen aus Erwartungswerten) ein, so können wir auch den Parameter g110 mit Erwartungswerten ausdrücken (Gleichungen (7.5) und (7.6): \\[\\begin{align} E(Y|X=1,K=1)=&amp; g_{000} + g_{010} \\times I_{K=1} + (g_{100} + g_{110} \\times I_{K=1}) \\times I_{X=1}\\notag\\\\ =&amp; g_{000} + g_{010} \\times 1 + (g_{100} + g_{110} \\times 1) \\times 1\\notag\\\\ =&amp; E(Y|X=0,K=0) + [E(Y|X=0,K=1) - E(Y|X=0,K=0)]+ \\notag\\\\ &amp; + [E(Y|X=1,K=0) - E(Y|X=0,K=0)] + g_{110} \\tag{7.5} \\end{align}\\] Zwei der Erwartungswerte in Gleichung (7.5), dritten Zeile, können herausgekürzt werden, anschließend g110 freigestellt werden: \\[\\begin{align} E(Y|X=1,K=1) =&amp; E(Y|X=0,K=1) + [E(Y|X=1,K=0) - E(Y|X=0,K=0)] +\\\\ &amp; +g_{110}\\\\ g_{110} =&amp; [E(Y|X=1,K=1) - E(Y|X=0,K=1)] -\\\\ &amp;-[E(Y|X=1,K=0) - E(Y|X=0,K=0)]\\\\ \\tag{7.6} \\end{align}\\] Inhaltlich bedeutet dies: Der Parameter g110 schätzt wie sehr der Effekt von \\(\\small X\\) auf \\(\\small Y\\) unter der Bedingung \\(\\small K=1\\) \\(\\small [E(Y|X=0,K=1) - E(Y|X=1,K=1)]\\) vom Effekt von \\(\\small X\\) auf \\(\\small Y\\) unter der Bedingung \\(\\small K=0\\) \\(\\small [E(Y|X=1,K=0) - E(Y|X=0,K=0)]\\) abweicht. Bzw: Der geschätzte Effekt von \\(\\small X\\) auf \\(\\small Y\\) ist unter der Bedingung \\(\\small K=1\\) um den Parameter g110 größer als unter der Bedingung \\(\\small K=0\\). Beachte: Wenn du eine bedingte lineare Regression und eine zweifache lineare Regression für den jeweils selben Datensatz durchführt und es keine Interaktion gibt (wenn die deskriptive Interaktion – unabhängig von ihrer Signifikanz – exakt den Wert Null annimmt), so sind die Parameter g000, g010 und g100, die in beiden Fällen geschätzt werden, identisch. Wenn im Datensatz allerdings Interaktionen auftreten werden sich die geschätzten Parameter in beiden Fällen unterscheiden. 7.2.1.2.2 Parameter g110 als Interaktion verstehen Eine Interaktion drückt aus, dass ein Effekt unter bestimmten Bedingungen unterschiedlich ausfällt. Bezogen auf unser Beispiel heißt das, dass der Effekt einer Behandlung auf den Gesundheitsscore von Patienten unter der Bedingung subjektiv zu geringer sozialer Unterstützung \\(\\small (K=0)\\) evtl. anders ausfällt als unter der Bedingung subjektiv ausreichender sozialer Unterstützung \\(\\small (K=1)\\). Um zu prüfen ob sich der Treatmenteffekt zwischen den beiden Bedingungen unterscheidet, bilden wir die Differenz beider Effekte: Ist die Differenz nicht gleich Null, so unterscheiden sich die Effekte unter den verschiedenen Bedingungen zumindest deskriptiv voneinander. Den Treatment-Effekt unter der Kovariaten-Bedingung \\(\\small K=0\\), beschrieben durch den Parameter g100, hatten wir bisher wie folgt ausgedrückt: \\(\\small E(Y|X=1,K=0) - E(Y|X=0,K=0)\\). Den Treatmenteffekt unter der Bedingung \\(\\small K= 1\\) (nicht durch einen eigenen Parameter abgebildet) könnte man synonym dazu wie folgt ausdrücken: \\(\\small E(Y|X=1,K=1) - E(Y|X=0,K=1)\\). Subtrahiert man den Treatmenteffekt unter der Bedingung \\(\\small K=0\\) vom Treatmenteffekt unter der Bedingung \\(\\small K= 1\\), so testet man, ob die Treatmenteffekte unter beiden Bedingungen identisch sind, bzw.: Man beschreibt die Interaktion aus Treatment (\\(\\small X\\)) und Kovariate (\\(\\small K\\)). Auf diesem Wege erhält man den selben Term, den wir auch schon in Gleichung (7.6) zuvor hergeleitet haben: \\[\\begin{align} IA_{X \\times K} =&amp; E(Y|X=1,K=1) - E(Y|X=0,K=1) – [E(Y|X=1,K=0) - E(Y|X=0,K=0)]\\\\ =&amp; g_{110} \\tag{7.7} \\end{align}\\] 7.2.1.2.3 Zusammengefasst Parameter Ausdruck in Erwartungswerten Ausdruck in Worten g000 \\(\\small E(Y|X=0,K=0)\\) Erwartungswert von \\(\\small Y\\) unter der Beingung \\(\\small X=0,K=0\\) g010 \\(\\small E(Y|X=0,K=1) - E(Y|X=0,K=0)\\) Der geschätzte „Effekt“ von \\(\\small K\\) auf \\(\\small Y\\) unter der Bedingung \\(\\small X=0\\) g100 \\(\\small E(Y|X=1,K=0) - E(Y|X=0,K=0)\\) Der geschätzte Effekt von \\(\\small X\\) auf \\(\\small Y\\) unter der Bedingung \\(\\small K=0\\) g110 \\(\\small [E(Y|X=1,K=1) - E(Y|X=0,K=1)]- \\\\ \\small - [E(Y|X=1,K=0) - E(Y|X=0,K=0)]\\) Die Interaktion \\(\\small X\\times K\\) 7.2.2 Kontinuierliche Kovariate, zweistufige Treatmentvariable Wir verwenden zur Veranschaulichung das gleiche Beispiel, dass wir schon bei der zweifachen linearen Regression verwendet haben, nur lassen wir jetzt die Annahme außen vor, dass es keine Interaktion zwischen Treatment-Variable und Kovariate gibt. Beispiel 6 Abhängige Variable \\(\\small Y\\): Gesundheitsscore von Patienten. Treatmentvariable \\(\\small X\\): Erhalten Patienten eine (\\(\\small X=1\\)) oder erhalten sie (\\(\\small X=0\\)) keine Behandlung. Kovariate \\(\\small Z_1\\): Einschätzung der subjektiv erfahrenen sozialen Unterstützung auf einer Skala von \\(\\small1-10\\). Wie schon bei der Parameter-Interpretation für kontinuierliche Kovariaten der zweifachen linearen Regression beschrieben, werden, anders als im Modell mit kategorialen Kovariaten, für kontinuierliche Kovariaten keine Indikatorvariablen gebildet. Stattdessen werden Parameter geschätzt, die zur Schätzung bedingter Ausprägungen von \\(\\small Y\\) direkt mit dem entsprechenden Wert für \\(\\small Z_1\\) multipliziert werden können. Interessiert mich also der Gesundheitsscore von Patienten mit einer bestimmten Ausprägung \\(\\small z_i\\) in der subjektiven sozialen Unterstützung können wir \\(\\small z_i\\) direkt in unsere Regressionsgleichung einfügen. Die Regressionsgleichung wird von EffectLiteR über folgendes Modell geschätzt: Figure 7.2: Regressionsmodell mit zweistufiger Treatmentvariable und kontinuierlicher Kovariate Das Modell entspricht dem der zweifachen linearen Regression, ergänzt um den Parameter g101. Die Parameter g000, g001 und g100 können auf vergleichbare Art und Weise durch Erwartungswerte ausgedrückt werden, wie bei der zweifachen linearen Regression mit zweistufiger Treatmentvariablen und kontinuierlicher Kovariaten. Anders als bei der zweifachen linearen Regression müssen hier jedoch die Bedingungen von \\(\\small X\\) und von \\(\\small K\\), unter denen ein Effekt geschätzt wird, beachtet werden. 7.2.2.1 g000 \\[\\begin{align} g_{000} = E(Y|X=0, Z_1=0) \\tag{7.8} \\end{align}\\] Der Parameter g000 schätzt die Ausprägung des Regressanden unter der Bedingung \\(\\small X = 0\\) und \\(\\small Z_1 = 0\\) (siehe Gleichung (6.6). 7.2.2.2 g001 \\[\\begin{align} g_{001} = E(Y|X=0, Z_1=1) - E(|IX=0,Z_1=0) \\tag{7.9} \\end{align}\\] Der Parameter g001 schätzt den Effekt der Kovariaten, den eine Veränderung von \\(\\small Z_1=0\\) zu \\(\\small Z_1=1\\) unter der Bedingung \\(\\small X=0\\) auf \\(\\small Y\\) ausübt(siehe Gleichung (6.8). Anders als bei der linearen zweifachen Interaktion ist die Bedingung \\(\\small X=0\\) hier von Bedeutung: Da eine Interaktion zwischen \\(\\small X\\) und \\(\\small Z_1\\) nicht ausgeschlossen wird, ist der Effekt der Kovariaten \\(\\small Z_1\\) auf \\(\\small Y\\) unter einer anderen Ausprägung der Treatmentvariablen gegebenenfalls ein anderer. 7.2.2.3 g100 \\[\\begin{align} g_{100} = E(Y|X=1,Z_1=0) - E(Y|X=0,Z_1=0) \\tag{7.10} \\end{align}\\] Der Parameter g100 schätzt den Treatmenteffekt, den eine Veränderung von \\(\\small X=0\\) zu \\(\\small X=1\\) unter der Bedingung \\(\\small K=0\\) auf \\(\\small Y\\) ausübt (siehe Gleichung (6.10). Beachte auch hier, dass die Bedingung \\(\\small Z=0\\) von Bedeutung ist. Wurde die kontinuierliche Variable z-Standardisiert (bzw. hat sie einen Mittelwert von Null) so schätzt g100 den durchschnittlichen Effekt der Veränderung der Treatmentvariablen von \\(\\small X=0\\) zu \\(\\small X=1\\). Der durchschnittliche Effekt beschreibt die erwartete Abweichung in der Ausprägung der abhängigen Variablen von Personen mit durchschnittlicher Ausprägung der Kovariaten \\(\\small Z_1\\) zwischen den unterschiedlichen Treatmentbedingungen (\\(\\small E(Y|X=1,Z_1=\\bar{z}_1=0)-E(Y|X=0,Z_1=\\bar{z}_1=0)\\)). Dass der durchschnittliche Effekt von einem Haupteffekt, wie er von einer ANOVA berechnet würde, abweicht, ist dann wahrscheinlich, wenn ein unbalanciertes Design vorliegt, das heißt wenn verschieden viele Beobachtungen in den unterschiedlichen Zellen vorliegen. Beachte: Wie schon für kategoriale Kovariaten erklärt gilt auch hier: Wenn du eine bedingte lineare Regression und eine zweifache lineare Regression für den jeweils selben Datensatz durchführst und es keine Interaktion gibt (wenn die deskriptive Interaktion der bedingten linearen Regression – unabhängig von ihrer statistischen Signifikanz – exakt den Wert Null annimmt) werden die Parameter der zweifachen linearen Regression (in unserem Beispiel g000, g010 und g100) identisch mit den entsprechenden Parametern der bedingten linearen Regression sein. Wenn im Datensatz allerdings Interaktionen auftreten, werden sich die geschätzten Parameter unterscheiden. 7.2.2.4 Parameter g101 Die Interpretation des Parameters g101 für kontinuierliche Kovariaten weicht für die bedingte lineare Regression nicht wesentlich von der Interpretation des Parameters g110 für kategoriale Kovariaten ab. Für kategoriale Kovariaten hatten wir in Gleichung (7.6) hergeleitet: \\[\\begin{align} g_{110} = [E(Y|X=1,K=1) - E(Y|X=0,K=1)] - [E(Y|X=1,K=0) - E(Y|X=0,K=0)] \\tag{7.11} \\end{align}\\] Diese Gleichung lässt sich auch auf kontinuierliche Kovariaten übertragen: \\[\\begin{align} g_{101} = E(Y|X=1,Z_1=1) - E(Y|X=0,Z_1=1) - [E(Y|X=1,Z_1=0) - E(Y|X=0,Z_1=0)] \\tag{7.12} \\end{align}\\] wurde die Kovariate \\(\\small Z_1\\) zuvor z-Standardisiert ist der Parameter g101 wie folgt zu interpretieren: Eine Veränderung der Kovariaten \\(\\small Z_1\\) um plus eine Standardabweichung verändert den Effekt des Treatments auf die abhängige Variable um den Parameter g101. Wurde die Kovariate nicht z-Standardisiert, so drückt der Parameter die erwartete Veränderung des Effektes von \\(\\small X\\) auf \\(\\small Y\\) bei einer Steigerung der Kovariaten \\(\\small Z_1\\) um eine Einheit ihrer Skala aus. In unserem Beispiel 6, nach z-Standardisierung der Kovariaten subjektive soziale Unterstützung: Steigt die subjektive soziale Unterstützung um eine Standardabweichung verändert sich der Effekt der Behandlung auf den Gesundheitsscore um g101 Punkte (der Skala des Gesundheitsscores). Bei Berechung des Beispiels 6 ohne vorherige z-Standardisierung von subjektiver sozialer Unterstützung drückt g101 die Steigerung im Erwarteten Effekt aus, die auftritt, wenn subjektive soziale Unterstützung um den Wert 1 (auf ihrer neunstufigen Skala) steigt. 7.3 Hauptoutput Der Hauptoutput weist nur in bestimmten Punkten Unterschiede zum Hauptoutput der zweifaktoriellen linearen Regression auf, nur diese Punkte werden hier detailiert behandelt, in allen anderen wird auf die zweifache lineare Regression verwiesen. 7.3.1 Variables Siehe Hauptoutput der zweifaktoriellen linearen Regression. 7.3.2 Regression Model Der einzige Unterschied zum Regression Model der zweifachen linearen Regression ist, dass nun im Parameter-Output auch Interaktionsparameter geschätzt werden. Dadurch, dass Interaktionen zugelassen werden ändern sich auch die Schätzwerte für die anderen Parameter im Vergleich zu Parametern der zweifachen linearen Regression für die gleichen Daten. 7.3.3 Cell Counts Siehe Hauptoutput der zweifaktoriellen linearen Regression. 7.3.4 Main Hypotheses Figure 7.3: Haupt-Hypothesen-Tests der bedingten linearen Regression 7.3.4.1 Hypothesentest 1 Getestet wird die Nullhypothese, dass die Erwartungswerte für alle Effektfunktionen gleich null sind. Im Screenshot hat die Treatment-Variable drei Ausprägungen, dementsprechend gibt es zwei Effektfunktionen [\\(\\small g1(K)\\) und \\(\\small g2(K)\\)] die laut der Nullhypothese beide im Durchschnitt den Wert Null annehmen. Dies könnte auch wie folgt ausgedrückt werden: \\(\\small E(g0) = E(g1) = E(g2)\\). In der Gleichungs-Schreibweise ist leichter nachvollziehbar, woher sich die Anzahl der Freiheitsgrade (\\(\\small df=2\\)) ergibt (Die Freiheitsgerade errechnen sich durch die Anzahl miteinander verglichener Gruppen minus eins). Wird der Test der Nullhypothese signifikant (\\(\\small p &lt; 0.05\\)) muss die Hypothese verworfen werden und man kann davon ausgehen, dass mindestens ein durchschnittlicher Treatmenteffekt vorhanden ist, wird der Test nicht signifikant kann die Nullhypothese angenommen werden (unter der Annahme, dass die Power der berechnteten Regressionsanalyse ausreichend groß ist). Bemerke: Wenn die Effektfunktionen im Durchschnitt den Wert Null annehmen, bedeutet das nicht unbedingt, dass es keine bedingten Treatmenteffekte gibt (dies wird von Hypothesentest 4 getestet): Es kann sein, dass sich der Effekt des Treatments unter einer Bedingung von \\(\\small K\\) gegenläufig zum Effekt des Treatments unter einer anderen Bedingung \\(\\small K\\) verhält und somit im Durchschnitt kein Effekt gefunden wird. Zur Verdeutlichung dieses Tatsache ein Beispiel: Es kann sein, dass eine Behandlung für Personen mit Krankheit A wirksam ist, für Personen mit Krankheit B jedoch schädlich. Ist dies der Fall, kann es passieren, dass die Behandlung für eine gemischte Gruppe von Personen mit den Krankheiten A oder B keinen durchschnittlichen Effekt aufweist, aber Effekte unter Der Bedingung “Krankheit A” und “Krankheit B” jeweils\" signifikant werden. 7.3.4.2 Hypothesentest 2 Die Hypothesentests 2 und 3 testen, ob die Kovariate(n) Einflüsse auf die abhängige Variable haben. Hypothesentest 2 testet, ob ein solcher Einfluss in der Referenzgruppe vorliegt, Hypothesentest 3 prüft, ob sich Einflüsse der Kovariten unter den anderen Treatment-Bedingungen (in den Gruppen, die nicht die Referenzgruppe sind) von den Einflüssen der Kovariaten in der Referenzgruppe unterscheiden. Hypothesentest 2 testet, ob es in der Kontrollgruppe Einflüsse der Kovariaten gibt. Gibt es keine Einflüsse (dies entspräche der getesteten Nullhypothese) so ist der Erwartungswert der Referenzgruppe unter allen Bedingungen von \\(\\small K\\) identisch (bzw: \\(\\small g0(K)\\) ist konstant). Für das im Screenshot oben abgebildete Beispiel mit zwei möglichen Kovariaten-Ausprägungen ließe sich die Nullhypothese also wie folgt aufschreiben: \\(\\small E(Y|X=0,K=0) = E(Y|X=0,K=1)\\). Da zwei Gruppen miteinander verglichen werden, haben wir (\\(\\small df= 2-1\\)) einen Freiheitsgrad. Alternativ könnte man die Nullhypothese auch wie folgt ausdrücken: \\(\\small g_{110} = 0\\) Für das Beispiel in 7.3 im Screenshot wird der Hypothesentest signifikant, das heißt die Nullhypothese kann verworfen werden. Mit einer Wahrscheinlichkeit von 96,01% (\\(\\small 1-\\)p-value) verändert sich der Erwartungswert des Gesundheitsscores (abhängige Variable) auf Populationsebene in der Gruppe die keine Behandlung erhält (\\(\\small X=0\\)) in Abhängigkeit der Ausprägung der Kovariaten auf Populationsebene. 7.3.4.3 Hypothesentest 3 Die Nullhypothese des dritten Tests geht davon aus, dass die Kovariate(n) in der Referenzgruppe die gleichen Auswirkungen hat/haben, wie in den anderen Gruppen. Sie geht also davon aus, dass es keine Interaktionen zwischen Kovariate(n) und Treatmentvariable gibt. Im Screenshot oben (7.3) lässt sich dies wie folgt mit Erwartungswerten ausdrücken: \\(\\small E(Y|X=1,K=0) = E(Y|X=1,K=1)\\) und \\(\\small E(Y|X=2,K=0) = E(Y|X=2,K=1)\\). Wir haben also zwei Vergleiche zwischen zwei Gruppen, woraus sich die Anzahl der Freiheitsgrade [\\(\\small df= 2\\times (2-1)=2\\)] ableiten lässt. Alternativ lässt sich die Nullhypothese auch wie folgt ausdrücken: \\(\\small g110 = g210 = 0\\). Wird die Nullhypothese signifikant muss sie verworfen werden und es kann davon ausgegangen werden, dass es mindestens eine Interaktion zwischen Kovariate(n) und Treatmentvariable gibt, wird der Test nicht signifikant, kann bei ausreichender Teststärke davon ausgegangen werden, dass keine Interaktionen vorliegen. Werden Hypothesentest 2 und Hypothesentest 3 beide nicht signifikant, kann, bei ausreichender Teststärke, davon ausgegangen werden, dass die Kovariate gar keinen Effekt auf die abhängige Variable ausübt: Hypothesentest 2 testet ob es einen Kovariaten-Effekt in der Referenzgruppe gibt, Hypothesentest 3 testet, ob der Effekt in der Referenzgruppe identisch zum Effekt in den anderen Gruppen ist. Werden beide Tests nicht signifikant bedeutet dies also: Es gibt keinen Effekt in der Referenzgruppe (Test 2) und in den anderen Gruppen sieht das genauso aus (Test 3). 7.3.4.4 Hypothesentest 4 Hypothesentest 4 testet ob irgend ein bedingter Effekt signifikant ist. Die Nullhypothese ist also erfüllt, wenn alle Effektfunktionen unter allen Ausprägungen der Kovariaten gleich Null sind bzw. nicht signifikant von Null abweichen. Im Screenshot oben (7.3) gibt es zwei Effektfunktionen und zwei Ausprägungen von \\(\\small K\\). Getestet wird also ob die Gleichungen \\(\\small g1(K) = g2(K) = 0\\) sowohl unter der Bedingung \\(\\small K=0\\), als auch unter der Bedingung \\(\\small K=1\\) gelten. In anderen Worten: es wird getestet, ob der Erwartungswert der abhängigen Variable unter der Bedingung \\(\\small K=0\\) und unter der Bedingung \\(\\small K=1\\) jeweils unter allen Bedinungen von \\(\\small X\\) identisch ist, es wird also getestet ob gilt: \\(\\small E(Y|X=0, K=0) = E(Y|X=1, K=0) = E(Y|X=2, K=0)\\) und \\(\\small E(Y|X=0, K=1) = E(Y|X=1, K=1) = E(Y|X=2, K=1)\\). In dieser zweiten Schreibweise lässt sich auch besser erkennen, warum der Test vier Freiheitsgrade hat. Wir Vergleichen zweimal drei Gruppen miteinander, es ergeben sich zwei Freiheitsgrade aus dem Vergleich der drei Erwartungswerte unter der Bedingung \\(\\small K=0\\) und zwei weiere Freiheitsgrade aus dem Vergleich der drei Erwartungswerte unter der Bedingung \\(\\small K=1\\): (\\(\\small df= 2 \\times (3-1) =4\\)). Eine dritte Möglichkeit die Nullhypothese für Hypothesentest 4 zu beschreiben gibt es auf Ebene der Regressionsparameter: \\(\\small g1(K) = g2(K) = 0\\) ist auch dann erfüllt, wenn alle Parameter innerhalb der Effektfunktionen gleich Null sind, wenn also gilt: \\(\\small g_{100} = g_{110} = g_{200} = g_{210} = 0)\\). Wird der Test signifikant (\\(\\small p &lt; 0.05\\)) muss die Hypothese verworfen werden und man kann davon ausgehen, dass mindestens einer der Parameter der Effektfunktionen ungleich null ist bzw. dass mindestens eine Ausprägung der Treatmentvariable \\(\\small X\\) unter mindestens einer der Ausprägungen der Kovariate \\(\\small K\\) einen Effekt auf die abhängige Variable \\(\\small Y\\) ausübt. 7.3.5 Adjusted Means Wie bei der einfachen linearen Regression werden Mittelwerte für die Ausprägung der abhängigen \\(\\small Y\\)-Variablen unter verschiedenen Bedingungen von \\(\\small X\\) angezeigt. Die adjustierten Mittelwerte lassen sich im Fall der bedingten linearen Regression genauso interpretieren, wie im Hauptoutput der einfaktoriellen Regression, da über alle weiteren Kovariaten gemittelt wird. Zu beachten ist, dass adjustierte Mittelwerte in unbalncierten Designs (bei unterschiedlich vielen Fällen in den Zelle) von Marginal Means, wie sie zur Berechnung von Haupteffekten verwendet werden, abweichen. Lese hierzu den Exkurs adjustierte Mittelwerte. 7.3.6 Average Effects Die durchschnittlichen Effekte lassen sich im Fall der bedingten linearen Regression genauso interpretieren, wie im Hauptoutput der einfaktoriellen Regression erklärt, da über den zweiten Faktor, die Kovariate, gemittelt wird: Es werden die durchschnittlichen Effekte der Treatmentvariablen geschätzt. Zum Unterschied zwischen durchschnittlichen Effekten (kategorialer Kovariaten) und Haupteffekten einer ANOVA lese den Exkurs adjustierte Mittelwerte. 7.3.7 Effects given a Treatment Condition In manchen Fällen und für manche Fragestellungen sind die durchschnittlichen Effekte nicht besonders informativ und Effekte unter einer Treatment-Condition aussagekräftiger. Was Effekte unter der Bedingung einer Treatment-Condition darstellen, wird an einem Beispiel beschrieben, versetze dich in folgendes Quasiexperiment hinein: Beispiel 7 Der Effekt einer neuen Therapie für eine bestimmte Krankheit wird getestet. Aus ethischen Gründen erhalten alle Patienten des Krankenhauses, die einen schweren Krankheits-Verlauf haben, die neue Therapie. Als Kontrollgruppe werden Patienten mit einem milderen Krankheits-Verlauf herangezogen, die mit der bisher verwendeten wenig erfolgreichen Therapie behandelt werden. Als Prädiktoren für den Gesundheitszustand nach Therapieende werden nicht nur die Therapieform sondern auch der Gesundheitszustand der Patienten vor Therapiebeginn herangezogen. Treatmentvariable: neue (EG) versus alte (KG) Therapieform. Abhängige Variable: Gesundheitsscore zu t2 (nach Therapieende). Kontinuierliche Kovariate: Gesundheitsscore zu t1 (vor Therapiebeginn). Dadurch dass die Probanden den Treatmentbedingungen nicht randomisiert zugeordnet wurden, erhalten wir ein Quasi-Experiment. EG und KG unterscheiden sich vor Therapiebeginn in Bezug auf die Kovariate: Die Kontrollgruppe mit milderem Krankheits-Verlauf hat vor Therapiebeginn einen höheren Gesundheitsscore. Figure 7.4 verdeutlicht, wie der durchschnittliche Effekt ermittelt wird: Eine Regression für die Kontrollgruppe und eine Regression für die Experimentalgruppe werden geschätzt, die durchschnittliche Differenz der Erwartungswerte beider Regressionen (das heißt der Durchschnitt der eingezeichneten erwarteten Effekte unter den empirisch erfassten Kovariaten-Ausprägungen) bildet den durchschnittlichen Effekt. In der Abbildung kann der durchschnittliche Effekt als Durchschnitt aller eingezeichneten senkrechten Linien zwischen den Regressionsgeraden verstanden werden. Figure 7.4: Graphische Veranschaulichung der Berechnung verschiedener Effekte Im Beispiel hat der Gesundheitsscore zu t1 unter beiden Treatmentbedingungen Auswirkungen auf den Gesundheitsscore zu t2 (die Regressionsgeraden in beiden Treatmentgruppen steigen). Die Auswirkung des Gesundheitsscores zu t1 auf den Gesundheitsscore in t2 ist unter der Bedingung X=0 größer als unter der Bedingung X=1 (es liegt eine Interaktion zwischen Treatmentbedingung und Kovariate vor). Die Distanz zwischen den Regressionsgleichungen unter den beiden Treatmentbedingungen (Der Treatment-Effekt) wird immer kleiner, je größer der Gesundheitsscore vor Terapiebeginn war. Da die durchschnittliche Ausprägung des Gesundheitsscores zu t1 in beiden Gruppen unterschiedlich ist, ist auch der Treatment-Effekt in beiden Gruppen unterschiedlich. In Figure 7.4 können die Treatmenteffekte given a Treatment-Condition als Durchschnitt der senkrechten Linen, die einer bestimmten Treatmentbedingung zugeordnet werden, verstanden werden. Der Treatment-Effekt in der Kontrollgruppe (\\(\\small E[g1(Z_1)|X=0]\\)) schätzt in Beispiel 7 also den Effekt der neuen Behandlung im Vergleich zur alten Behandlung für Personen mit mildem Krankheitsverlauf, der Treatment-Effekt in der Experimentalgruppe (\\(\\small E[g1(Z_1)|X=0]\\)) schätzt den selben Effekt für Personen mit schwerem Krankheitsverlauf. 7.3.8 Effects given K=k (nur bei einer kategorialen Kovariaten) Hier werden Effekte der Treatment-Bedingungen unter den verschiedenen Ausprägungen kategorialer Kovariaten auf die abhängige Variable abgebildet. (#fig:bed_kisK)Effects given K=k Die \\(\\small g1(K)\\)-Funktion beschreibt in der Modellgleichung den Effekt von \\(\\small X=1\\) auf \\(\\small Y\\). \\(\\small E[g1(K)|K=0]\\) schätzt genau diesen Effekt für Menschen mit einer Kovariaten-Ausprägung von \\(\\small K=0\\). Die Effektgröße, die als Cohens D oder Glass‘ Delta interpretiert werden kann, entspricht dem Schätzwert der bedingten Effekte, standardisiert an der Standareabweichung der abhängigen Variable \\(\\small Y\\) in der Referenzgruppe. Im Screenshot (@ref(fig:bed_kisK)) kann der Effekt \\(\\small E[g1(K)|K=0]\\) wie folgt interpretiert werden: Für Menschen mit der Kovariaten-Ausprägung \\(\\small K=0\\) vergrößert das Treatment \\(\\small X=1\\) die Outcome-Variable \\(\\small Y\\) um schätzungsweise 15.2 Punkte im Vergleich zu Treatment \\(\\small X=0\\). Der Standardfehler (SE) des Effektes liegt bei 1.70 Punkten. Das Treatment ist für Personen mit der Kovariatenausprägung \\(\\small K=0\\) mit an Sicherheit grenzender Wahrscheinlichkeit wirksam (\\(\\small p = 0.00e+00\\) bedeutet, dass \\(\\small p\\) so klein ist, dass EffectLiteR die Zahl nicht mehr anzeigt). 7.3.9 Hypotheses given K=k (nur bei kategorialen Kovariaten): Hier werden Hypothesen über durchschnittliche Effekte unter bestimmten Bedingungen von K getestet. Figure 7.5: Hypotheses given K=k 7.3.9.1 Hypothesentest K1 Die Nullhypothese geht davon aus, dass es für Personen mit der Kovariaten-Ausprägung \\(\\small K=0\\) keine Effekte von \\(\\small X\\) auf \\(\\small Y\\) gibt. In Figure 7.5 (Screenshot ähnelt der Auswertung von Beispiel 5, allerdings gibt es drei Treatment-Bedingungen: X=0 steht für keine Behandlung, X=1 und X=2 für zwei verschiedene Behandlungs-Arten) gibt es nur eine zweistufige kategoriale Kovariate K und eine dreistufige Treatmentvariable, entsprechend besagt die Nullhypothese von K1: Es gibt keinen Effekt des Treatments unter der Bedingung \\(\\small K=0\\), bzw. der Erwartungswert von \\(\\small Y\\) ist unter der Bedingung \\(\\small K=0\\) von \\(\\small X\\) unabhängig: \\(\\small E(Y|X=0,K=0) = E(Y|X=1,K=0) = E(Y|X=2,K=0)\\). Der Vergleich von drei Gruppen lässt auf zwei Freiheitsgrade des Testes schließen: \\(\\small df=3-1=2\\). Der Effekt von \\(\\small X=1\\) auf \\(\\small Y\\) unter der Bedingung \\(\\small K=0\\) wird durch den Parameter g100 beschrieben, der Effekt von \\(\\small X=2\\) auf \\(\\small Y\\) unter der Bedingung \\(\\small K=0\\) wird durch den Parameter g200 beschrieben. Alternativ lässt sich die Nullhypothese dementsprechend mit der Gleichung \\(\\small g_{100} = g_{200} = 0\\) formulieren und interpretieren. Im Beispiel wird der Hypothesentest signifikant (\\(\\small p &lt; 0.05\\)), wir können die Nullhypothese verwerfen, es gibt Treatment-Effekte für Personen mit der Kovariaten-Ausprägung \\(\\small K=0\\). 7.3.9.2 Hypothesentest K2 Die Nullhypothese geht davon aus, dass es für Personen mit der Kovariaten-Ausprägung \\(\\small K=1\\) keine Effekte von \\(\\small X\\) auf \\(\\small Y\\) gibt. In Figure 7.5 gibt es nur eine zweistufige kategoriale Kovariate \\(\\small K\\) und eine dreistufige Treatmentvariable, entsprechend besagt die Nullhypothese von K2: Es gibt keinen Effekt des Treatments unter der Bedingung \\(\\small K=1\\), bzw. der Erwartungswert von \\(\\small Y\\) ist unter der Bedingung \\(\\small K=1\\) von \\(\\small X\\) unabhängig: \\(\\small E(Y|X=0,K=0) = E(Y|X=1,K=0) = E(Y|X=2,K=0)\\). Der Vergleich von drei Gruppen lässt auf zwei Freiheitsgrade schließen: \\(\\small df=3-1=2\\). Der Effekt von \\(\\small X=1\\) auf \\(\\small Y\\) unter der Bedingung \\(\\small K=1\\) wird durch die Summe der Parameter g100 + g110 beschrieben, der Effekt von \\(\\small X=2\\) auf \\(\\small Y\\) unter der Bedingung \\(\\small K=0\\) wird durch die Summe der Parameter g200 + g210 beschrieben. Alternativ lässt sich die Nullhypothese dementsprechend auch durch die Gleichung \\(\\small g_{100}+g_{110} = g_{200}+g_{210} = 0\\) formulieren und interpretieren. Im Beispiel wird der Hypothesentest signifikant (\\(\\small p &lt; 0.05\\)), wir können die Nullhypothese verwerfen, es gibt Treatment-Effekte für Personen mit der Kovariaten-Ausprägung \\(\\small K=1\\). 7.4 Übungen “bedingte lineare Regression” Rechne eine bedingte lineare Regression mit Gesundheitsscore als abhängiger Variable, Behandlungsart als Treatmentvariable und subjektiver sozialer Unterstützung als kontinuierlicher Kovariate (Daten aus dem Übungsdatensatz). Beachte: Die inhaltliche Interpretation der Parameter wird durch z-Standardisierung der kontinuierlichen Kovariaten deutlich erleichtert! 7.4.1 A) Wird der Interaktionseffekt signifikant? Interpretiere die Aussage des Interaktionseffektes in Worten. Rechne mit dem selben Datensatz zusätzlich eine zweifache lineare Regression (d.h. deaktiviere Interaktionseffekte unter Options). Vergleiche Die Parameter g000, g001, g100 und g200 die in beiden Fällen geschätzt werden, was fällt dir auf? Welche Parameter erscheinen dir vertrauenserweckender, d.h. welche Effekte würdest du interpretieren und warum? 7.4.2 B) Ein Patient hat die Kovariatenausprägung \\(\\small z_1=8\\) (nach z-Standardisierung: \\(\\small z&#39;_1\\approx 1.784\\)) und wurde mit Behandlungsmethode 1 behandelt. Welcher Gesundheitsscore kann bei ihm erwartet werden? (Zur Beantwortung dieser Frage ist das Kapitel Conditional Effects hilfreich. Ein anderer Patient hat ebenfalls eine Kovariatenausprägung von z=8 (z’=xy), wurde aber noch nicht behandelt. Welche Behandlungsart würde ihm, basierend auf den vorliegenden Daten, vermutlich am besten helfen? (Zur Beantwortung dieser Frage ist das Kapitel Conditional Effects hilfreich. Lösungen und Videos zur Berechnung der Aufgaben findest du hier. "],
["exkadj.html", "8 Exkurs Adjustierte Mittelwerte", " 8 Exkurs Adjustierte Mittelwerte Bei der bedingten linearen Regression macht das Verfahren der Mittelwertsbildung einen Unterschied für den Fall, dass das Design bezüglich der Kovariaten nicht vollständig balanciert ist. Wie adjustierte Mittelwerte von \\(\\small Y\\) für die verschiedenen Ausprägungen von \\(\\small X\\) gebildet werden wird im Folgenden an einem Beispiel demonstriert: (#bspfünf) zu unserem Beispieldatensatz demonstriert (Treatmentvariable: Behandlungsart ist \\(\\small 0\\),\\(\\small 1\\) oder \\(\\small 2\\), Kovariaten: Subjektiv ausreichend soziale Unterstützungist \\(\\small 0\\) oder \\(\\small 1\\)). Beispiel 8 Abhängige Variable \\(\\small Y\\): Gesundheitsscore von Patienten. Treatmentvariable \\(\\small X\\): Erhalten Patienten Behandlungsart 1 (\\(\\small X=1\\)) oder Behandlungsart 2 (\\(\\small X=1\\)) oder erhalten sie keine Behandlung (\\(\\small X=0\\)). Kovariate \\(\\small K\\): Patient gibt an in seinem Umfeld ausreichend soziale Unterstützung zu erhalten (\\(\\small K=1\\)) bzw. nicht genug Unterstützung zu erhalten (\\(\\small K=0\\)). Die entsprechenden Daten finden sich auch in unserem Beispieldatensatz. Dem Output unter Cell Counts im Hauptoutput (siehe Figure 8.1) ist zu entnehmen, dass das Design im Beispiel unbalanciert ist: Unter der Bedingung \\(\\small K=0\\) liegen 116 Beobachtungen vor, unter der Bediungung \\(\\small K=1\\) liegen 184 Beobachtungen vor: Figure 8.1: Unbalanciertes Design Zur Bildung der adjustierten Mittelwerte werden zuerst bedingte Erwartungswerte für alle Ausprägungen von \\(\\small X\\) unter allen Ausprägungen der Kovariaten gebildet. Diesen Schritt haben die Berechnung von Randmittelwerten und adjustierten Mittelwerten noch gemeinsam. Die bedingten Erwartungswerte werden zur Veranschaulichung für alle Zellen, für die gilt \\(\\small X=0\\), berechnet (die bedingten Erwartungswerte unter der Bedingung \\(\\small X=1\\) werden nach dem selben Prinzip gebildet). Die Zahlenwerte für die Parameter g000 und g010 stammen aus der Analyse des Beispieldatensatzes für das Beispiel 8. Es ergeben sich: \\[\\begin{align} E(Y|X=0,K=1)&amp;= g000 + g010 \\notag\\\\ &amp;= 28,895 + 3,826\\notag\\\\ &amp;= 32,721 \\tag{8.1} \\end{align}\\] und \\[\\begin{align} E(Y|X=0,K=0)&amp;= g000\\\\ &amp;= 28,895 \\tag{8.2} \\end{align}\\] Der zweite Schritt bei der Bildung adjustierter Mittelwerte ist die bedingten Erwartungswerte für die Ausprägungen der Treatmentvariable zu mitteln. Dabei werdein die bedingten Erwartungswerte an der proportionalen Häufigkeit der Beobachtung der Ausprägungen der Kovariate gewichtet. Zur Veranschaulichung wird der adjustierten Mitteslwert für die Bedingung \\(\\small X=0\\) aus den oben berechneten bedingten Erwartungswerten (Gleichungen (8.1) und(8.2)) und den Informationen zur Anzahl an Beobachtungen unter den Bedingugne \\(\\small K=0\\) und \\(\\small K=1\\) aus Figure 8.1 berechnet: \\[\\begin{align} Adj.Mean0 &amp;= E(Y|X=0,K=1) \\times \\frac{N_{K=0}}{N} + E(Y|X=0,K=0) \\times \\frac{N_{K=1}}{N}\\\\ &amp;= 32,721 \\times \\frac{116}{116+184} + 28,895 \\times \\frac{184}{116+184}\\\\ &amp;= 30,374 \\tag{8.3} \\end{align}\\] Bei der Berechnung von Randmittelwerten würde eine Gewichtung der bedingten Erwartungswerte ausbleiben, das Randmittel für die Bedingung \\(\\small X=0\\) wäre also: \\[\\begin{align} Marginal.Mean0 &amp;= E(Y|X=0,K=1) \\times \\frac{1}{2} + E(Y|X=0,K=0) \\times \\frac{1}{2}\\\\ &amp;= 32,721 \\times \\frac{1}{2} + 28,895 \\times \\frac{1}{2}\\\\ &amp;= 31,5475 \\tag{8.4} \\end{align}\\] Vergleiche den so berechneten adjustierten Mittelwert mit dem Output in der folgenden Abbildung: Figure 8.2: Output Adjusted Means Die durchschnittlichen Effekte, die EffectLiteR ausgibt, basieren auf adjustierten Mittelwerten. Der durchschnittliche Effekt von Treatment \\(\\small X=1\\) ist also \\(\\small 46,0-30,4=15,6\\) (die gerundeten Zahlen stammen aus dem Output für adjustierte Mittelwerte (Figure 8.2), EffectLiteR nutzt zur Berechnung der adjustierten Effekte weniger stark gerundete Zahelnwerte). Haupteffekte, wie sie etwa von einer ANOVA geschätzt werden, basieren hingegen auf der Differenz der marginal Means. Wann ist die Verwendung adjustierter Mittelwerte angemessen und wann sind marginal Means vorzuziehen? Adjustierte Mittelwerte sollten immer dann den marginal Means vorgezogen werden, wenn der Anteil der Personen mit einer bestimmten Kovariatenausprägung \\(\\small K=k\\) in unserem Datensatz den Anteil der Personen mit der gleichen Kovariatenausprägung \\(\\small K=k\\) in der Gesamtpopulation widerspiegelt und somit durchschnittliche Treatment-Effekte berechnet werden können. In unserem Beispiel nehmen wir an 300 zufällige ausgewählte Patienten danach befragt zu haben, ob sie genügend soziale Unterstützung erhalten. Wenn 184 der Patienten berichten nicht genügend Unterstützung zu erhalten, so enthält dies eine Information, die wir abbilden, indem wir adjustierte Mittelwerte berechnen. Wenn wir uns ein Experimental-Design vorstellen, in dem wir probieren möglichst gleich viele Personen mit den Kovariaten-Ausprägung \\(\\small K=k_1\\) und \\(\\small K=k_2\\) zu erheben (Beispielsweise wenn wir den Effekt einer Behandlung gegen Krebs bei normalgewichtigen Patienten und bei anorektischen Patienten vergleichen), aber auf Grund eines Dropouts ungleich große große Gruppen erhalten, so haben wir zum einen nicht das Ziel einen durchschnittlichen Treatment-Effekt zu berechnen, zum anderen enthält unsere Gruppengröße keine relevanten Informationen. In diesem Fall sollten wir marginal Means zur Effektgrößen-Berechnung verwenden (passiert automatisch wenn die Berechnung etwa mit SPSS vorgenommen wird, SPSS hat bisher keine Funktion zur berechnung adjustierter Mittelwerte). Zusammengefasst: Entspricht das Verhältnis der Anzahl der Beobachtungen unter den verschiedenen Ausprägungen der Kovariaten in etwa dem Verhältnis in der Population, so können mit den von EffectLiteR berechneten, auf adjustierten Mittelwerten beruhenden, durchschnittlichen Effekten die Konsequenzen von Treatment-Maßnahmen auf die Gesamtpopulation besser abgeschätzt werden als mit Analysemethoden, die auf marginal Means beruhen. Beachte: In Studien, in denen evtl. Einflüsse der Kovariaten auf die Zuordnung zu den Treatmentbedingungen vorliegen (wenn sich z.B. vermehrt ältere Leute für die Treatmentbedingung zum Hörgeräte-Test und vermehrt jüngere Leute für die Kontrollbedingung melden und das Alter der Probanden Einflüsse auf die abhängige Variable aufweist), hat das hinzufügen konfundierter Kovariaten (in diesem Fall des Alters der Probanden) ebenfalls einen Einfluss auf die adjustierten Mittelwerte. Solche Kovariaten (das Alter) sollten also unbedingt als zusätzliche Kovariaten in die Regression aufgenommen werden, um fehlerhafte Effekt-Schätzungen zu vermeiden. "],
["conditional-effects.html", "9 Conditional Effects 9.1 Conditional Effects I 9.2 Conditional Effects II 9.3 Conditional Effects III 9.4 Conditional Effects IV", " 9 Conditional Effects Es gibt insgesamt vier Reiter im Output-Panel, die dabei helfen Bedingte Effekte unter verschiedenen Ausprägungen von Kovariaten zu interpretieren. Figure 9.1: Vier Conditional-Effects-Reiter Diese vier Reiter werden nun einer nach dem anderen besprochen. 9.1 Conditional Effects I Unter Conditional Effects I werden für jeden Fall des Datensatzes alle beobachteten Prädiktoren aufgelistet und die erwarteten Effekte unter diesen Bedingungen geschätzt. Figure 9.2: Conditional Effects I - Output Der erste beobachtete Fall ist also in der Treatmentgruppe \\(\\small X=2\\), hat auf der kategorialen Kovariate \\(\\small k1\\) die Ausprägung \\(\\small 0\\) und auf der kontinuierlichen Kovariaten \\(\\small z_1\\) die Ausprägung \\(\\small 0.576647\\) (\\(\\small K\\) ist dann relevant, wenn mehrere kategoriale Kovariaten vorliegen und von EffectLiteR automatisch zu einer kategorialen Variablen \\(\\small K\\) zusammengefasst werden). Unter diesen Prädiktor-Ausprägungen liegt der Erwartungswert der Effektfunktion \\(\\small g2(K)\\) bei \\(\\small -0.0555\\) und der Standardfehler bei \\(\\small 0.0869\\). Der Erwartungswert der abhängigen Variablen liegt bei \\(\\small ExpOutc2 = 0.0743\\). Die Angaben zur Effektfunktion \\(\\small g1(K)\\) und dem Expected Outcome unter den Bedingungen \\(\\small X=0\\) (ExpOutc0) und \\(\\small X=1\\) (Exp.Outc1) sind mehr theoretischer Natur, da der erste angezeigte Fall nun mal der Treatmentgruppe \\(\\small X=2\\) zugeordnet ist. Man kann die beiden Effektgrößen-Schätzer wie folgt interpretieren: Eine Person der Treatmentbedi 9.2 Conditional Effects II Unter dem zweiten Conditional Effects Reiter hat man die Möglichkeit die Kombination aus Kovariatenausprägungen, unter der die bedingten Treatmenteffekte geschätzt werden, selbst auszuwählen. Wählt man für die kontinuierlichen Kovariaten den unter Descriptive Statistics for Continous Covariates angegebenen Mittelwert aus (in Figure 9.3 beispielsweise \\(\\small z_1=0.0036\\)), so erhält man als Effekt den Schätzer des durchschnittlichen bedingten Treatment-Effektes unter den gewählten Bedingungen der kategorialen Kovariaten (in Figure 9.3 den Treatmenteffekt unter der Bedingung \\(\\small k1=male\\)). Figure 9.3: Conditional Effects II 9.3 Conditional Effects III Dieser Reiter ist dann hilfreich, wenn Vorhersagen für einzelne Fälle getroffen werden sollen, für die nicht alle Daten vorhanden sind. Angenommen wir haben einen großen Datensatz mit vielen Kovariaten, der erfasst für welche Patienten welche Therapieform wie effektiv ist. Wir wollen entscheiden, ob für einen bestimmten Patienten Therapie \\(\\small X=0\\), Therapie \\(\\small X=1\\) oder Therapie \\(\\small X=2\\) am effektivsten zu sein scheint. Der uns vorliegende Datensatz sagt Therapieerfolg anhand der Kovariaten \\(\\small k1\\), \\(\\small kateg2\\), \\(\\small Z_1\\), \\(\\small Z_2\\) und \\(\\small Z_3\\) vorher. Für den Patienten, für den wir die nach Möglichkeit erfolgreichste Therapie auswählen wollen, sind allerdings nur die Variablen für \\(\\small k1\\), \\(\\small Z_1\\) und \\(\\small Z_3\\) bekannt (\\(\\small k1 = male\\), \\(\\small Z_1\\) = 1.75, \\(\\small Z_3\\) = 1.75, siehe Figure 9.4). Im Reiter Conditional Effects III können die drei bekannten Kovariaten eingegeben werden, während für die unbekannten Kovariaten (\\(\\small kateg2\\) und \\(\\small Z_2\\) ) \\(\\small NA\\) angegeben werden kann. EffectLiteR mittelt dann die Effekte der ähnlichsten Fälle um Effekte für den gewählten Einzelfall zu schätzen. Figure 9.4: Conditional Effects III Gehen wir davon aus, dass eine hohe Ausprägung der abhängigen Variablen wünschenswert ist, so sollten wir für den Patienten die Therapieform \\(\\small X=0\\) wählen, denn \\(\\small ExpOutc0 &gt; ExpOutc2 &gt; ExpOutc1\\). Die Angabe der Standardfehler der aggregierten Effekte hilft dabei abzuschätzen, inwieweit der Vergleich der ausgegebenen Erwartungswerte bei inferenzstatistischer Testung signifikant würde. Ein t-Test wird beispielsweise dann signifikant, wenn die Mittelwerts-Differenz größer als 1.96 Standardfehler (gemittelt über beide Gruppen) ist. Es ist hilfreich zu verstehen, wie die dem gewählten Fall „ähnlichen“ Fälle ermittelt werden, deren gemittelte Effekte als Schätzer für die gesuchten Effekte genutzt werden. Aus dem Datensatz werden Fälle herausgesucht, die die gleichen kategorialen Kovariaten-Ausprägungen haben, wie der Fall, auf den geschlussfolgert werden soll. Unser Patient ist männlich (\\(\\small k1=0\\)), deshalb werden nur Daten von Männern betrachtet (siehe Kovariatenausprägungen unter \\(\\small k1\\) in Figure 9.5. Für kontinuierliche Kovariaten muss die Betrachtung von Fällen mit ähnlichen Kovariaten-Ausprägungen ausreichen, da identische Ausprägungen in der Regel selten sind. Unser Patient hat die Kovariaten-Ausprägungen \\(\\small z_1=1.75\\) und \\(\\small z_3=1.75\\). Im Beispiel (Figure 9.5) wurden also die Fälle von Männern ausgesucht, die dem ausgewählten Fall auf den Variablen \\(\\small Z_1\\) und \\(\\small Z_3\\) am ähnlichsten sind, die Ausgewählten Fälle haben auf der Variable \\(\\small Z_1\\) Ausprägungen zwischen \\(\\small 1,33\\) und \\(\\small 1,90\\) und auf der Variable \\(\\small Z_3\\) Ausprägungen zwischen \\(\\small 1,17\\) und \\(\\small 2,21\\). Figure 9.5: Conditional Effects III - Ähnliche Fälle Dass insgesamt 10 Fälle als ähnlich ausgewählt wurden, entspricht der Default-Einstellung, kann allerdings unter Number of rows frei ausgewählt werden. Wenn die Kovariaten-Ausprägungen der ausgewählten Fälle den Kovariaten-Ausprägungen des Falles, auf den geschlossen werden soll, stark ähneln, kann die Anzahl ausgewählter Fälle erhöht werden, weichen sie hingegen stark von den Kovariaten-Ausprägungen des Falles, auf den geschlossen werden soll, ab, sollte die Anzahl verringert werden. Die Auswahl der angegebenen Kovariaten sollte mit Bedacht geschehen. In unserem Beispiel betrachten wir einen männlichen Patienten. Da wir uns dazu entschieden das Geschleicht unter dem Conditional Effects III-Reiter anzugeben, werden nur Fälle anderer Männer in Betracht gezogen. Es ist also nur sinnvoll anzugeben, dass der Fall, auf den geschlossen werden soll, ein Mann ist, wenn das Geschlecht oder die Interaktion von Geschlecht und anderen Prädiktoren die abhängige Variable auch zu einem angemessenen Grad vorhersagen. Wenn das Geschlecht die abhängige Variable hingegen kaum vorhersagt, gibt man es besser nicht an, weil man damit die Zahl der Fälle, in denen nach ähnlichen Kovariaten-Ausprägungen gesucht wird, stark einschränkt. Das selbe Prinzip gilt auch für die Auswahl von kontinuierlichen Kovariaten. 9.4 Conditional Effects IV Der Reiter Conditional Effects IV kann dann verwendet werden, wenn lediglich eine einzige abhängige Variable bekannt ist. In diesem Reiter wird eine Regression der gewünschten Kovariate auf eine Effektfunktion geschätzt. Figure 9.6: Conditional Effects III - Output Der Output wird wie folgt interpretiert: Der geschätzte Effekt einer Veränderung von \\(\\small X=0\\) zu \\(\\small X=1\\) unter der Bedingung \\(\\small k=k0\\) ist \\(\\small 3,288\\), unter der Bedingung \\(\\small k=k1\\) ist der geschätzte Effekt um \\(\\small 1,409\\) kleiner als unter der Bedingung \\(\\small k=k0\\) und somit \\(\\small E[g1(x)|k1=1]=3,288-1,409=1,879\\) und unter der Bedingung \\(\\small k=k2\\) ist der geschätzte Effekt um \\(\\small -0,337\\) kleiner als unter der Bedingung \\(\\small k=k0\\) und somit \\(\\small E[g1(x)|k1=2]=3,288-0,337=2,951\\). Dir wird aufgefallen sein, dass unter Conditional Effects IV nicht von vornherein Standardfehler für die geschätzten Effekte berechnet werden. Zur formalen Berechnung von Standardfehlern müssen generell bestimmte Annahmen getroffen werden (beispielsweise ob der Zusammenhang zwischen Prädiktor und Regressand linear oder quadratisch ist, Annahmen über die Form der Verteilung, …). Für die Regression einer Kovariaten auf eine Effektfunktion sind solche Verteilungsannahmen nicht generell bekannt, deshalb wird von EffektLiteR kein Standardfehler geschätzt. Will man dennoch einen Standardfehler interpretieren kann man auf das Bootstrap-Verfahren zurückgreifen. Dabei werden auf Grundlage der Stichprobe verwandte Stichproben simuliert (durch zufälliges ziehen von Fällen „mit zurücklegen“, das heißt einige Fälle der Stichprobe werden gar nicht beachtet, andere Fälle mehrfach). Für jede simulierte Stichprobe wird die Regression der Kovariaten auf die Effektfunktion gerechnet, die Standardabweichung der so gefundenen Effektgrößenschätzer wird als Standardfehler interpretiert. Die Anzahl an Stichproben, die gezogen werden soll, kann der Nutzer unter Number of bootstrap draws frei angeben. Natürlich wird die Schätzung des Standardfehlers um so genauer, je mehr simulierte Stichproben gezogen werden, jedoch (Vorsicht!) dauert die Berechnung bei einer großen Zahl an Bootstraps auch entsprechend länger und kann nicht so einfach abgebrochen werden. "],
["plots.html", "10 Plots 10.1 Plot 1 10.2 Plot 2 10.3 Plot 3 10.4 Plot 4 10.5 Übung “Plots”", " 10 Plots EffectLiteR kann Graphiken erstellen, die die Übersichten über Zusammenhänge der gerechneten Regressionen verbessern. Hierfür gibt es vier verschiedene Reiter im Eingabepanel, die zur graphischen Verdeutlichung verschiedener Informationen gedacht sind. Figure 10.1: Vier Plot-Reiter In diesem Kapitel werden diese vier Reiter einer nach dem anderen behandelt. 10.1 Plot 1 Unter Plot 1 werden Histogramme mit Häufigkeiten aller Ausprägungen der abhängigen Variable für die untersuchten Zellen des Designs angezeigt (jede Ausprägungskombination der kategorialen Prädiktoren stellt eine Zelle dar). Solche Histogramme können beispielsweise als Hinweise dafür dienen, ob die abhängige Variable unter den verschiedenen Bedingungen normalverteilt ist, ob eine Schiefe in der Verteilung vorliegt oder ob es unter bestimmten Bedingungen Boden- oder Deckeneffekte gibt. Figure 10.2: Plot 1 Interpretation der Beispielgraphik (dreistufige Treatment-Variable, keine kategorialen Kovariaten): In keiner der Zellen liegen Decken- oder Bodeneffekte vor. In allen drei Zellen scheint die abhängige Variable mehr oder weniger normalverteilt zu sein, in Zelle \\(\\small 0\\)“ sieht die Normalverteilung minimal linksschief aus, was auf die Regression an sich keine großen Auswirkungen hat. Dass der Gipfel der Verteilung in Zelle \\(\\small 2\\) niedriger ist als in den anderen beiden Zellen, deutet auf einen Treatmenteffekt hin: Unter der Bedingung in Zelle \\(\\small 2\\) finden sich im Mittel weniger hohe Ausprägungen des Regressanden, als unter den anderen beiden Bedingungen. Betrachtet man eine Regression mit ausschließlich kontinuierlichen Kovariaten erhält man eine Zelle pro Ausprägung der Treatmentvariablen, betrachtet man Fälle mit ein oder mehreren kategorialen Variablen erhält man für jede Kombination von Treatmentvariablen- und kategorialen Kovariaten-Ausprägungen eine Zelle. Welche Zelle für welche Bedingung steht kann unter Variables im Hauptoutput nachgesehen werden. Es folgt ein Beispiel mit zwei kategorialen Kovariaten. In Figure 10.3 ist nicht nur der Output unter Plot 1 sondern zur Zuordnung der Zellen zu ihren Bedingungen auch der Variables-Output angezeigt. Figure 10.3: Plots 1 und Variables-Output in 3x2x2-Zellen-Design Interpretation der Beispielgraphik: Zelle \\(\\small 12\\) beschreibt die Bedingung \\(\\small X = treat1\\), \\(\\small K = 2\\). \\(\\small K\\) ist eine (von EffectLiteR) zusammengesetzte Kategorie: \\(\\small K=2\\) bedeutet \\(\\small k1=female\\) und \\(\\small kateg2=1\\). Die Verteilung für Zelle \\(\\small 12\\) zeigt also die Häufigkeitsverteilung der abhängigen Variable \\(\\small dv\\) für Frauen/Mädchen (\\(\\small k1\\)) der Gruppe \\(\\small treat1\\) mit der Ausprägung \\(\\small kateg2 = 2\\). 10.2 Plot 2 Plot 2 zeigt die Regressionsgerade einer kontinuierlichen Kovariaten \\(\\small Z\\) auf den Regressanden in jeder der Bereits unter Plot 1 beschriebenen Zellen. Figure 10.4: Plot 2 - Output Man kann erkennen, dass in Bereichen des Prädiktors, für die nur wenige Schätzwerte vorliegen (jeweils links und rechts außen) ein größerer bläulicher Schatten um die Regressionsgerade eingezeichnet ist, während dieser Schatten in Bereichen des Prädiktors, für die viele Schätzwerte vorliegen (jeweils in der Mitte) kleiner ist. Dieser blaue Schatten stellt den Standardfehler der Regression unter bestimmten Ausprägungen des Prädiktors dar. Eine solche Schätzung des Standardfehlers gelingt unter Annahme der probabilistischen Testtheorie: Anders als die klassische Testtheorie, die für eine Regression nur einen einzigen Gesamt-Reliabilitäts-Kennwert vorsieht, berücksichtigt die probabilistische Testtheorie, dass eine Regression in Bereichen, in denen viele Beobachtungen von Prädiktor und Regressand vorliegen, zu genaueren Vorhersagen fähig ist, als in Bereichen, in denen nur wenige Beobachtungen vorliegen. 10.3 Plot 3 Unter Plot 3 lassen sich Zusammenhänge zwischen den Effekt-Funktionen und anderen Variablen verdeutlichen. Der Abschnitt zu Plot 3 geht Schritt für Schritt durch die im linken Plot-Panel vorhandenen Eingabeoptionen (siehe Graphik unten) ein und behandelt zum Schluss noch einige Zusammenhänge zwischen den anzeigbaren Graphiken und den von EffectLiteR geschätzten Regressionsparametern aus dem Hauptoutput. Figure 10.5: Plot 3 - Input Möglichkeiten 10.3.1 Effect function und Regressor Auf der linken Seite kann die gewünschte Effekt-Funktion eingegeben werden und der Regressor gewählt werden. Wird eine kontinuierliche Kovariate als Regressor gewählt, so zeigt der Plot die geschätzten Effekte für jede empirische Ausprägung der Kovariaten an, durch diese geschätzten Effekte kann EffectLiteR einen Graph legen. Plot 3 lässt sich auch mit kategorialen Kovariaten erstellen, in diesem Fall kann kein Graph angezeigt werden, es werden lediglich Punkte für die geschätzten Effekte unter der angegebenen Bedingung angezeigt. Figure 10.6: Plot 3 - kategorialer vs. kontinuierlicher Regressor 10.3.2 Colour variable Plot 3 erlaubt eine Colour-Variable festzulegen, durch die der Zusammenhang mit einer dritten Variablen visualisierbar ist. In Figure 10.7 wurde die Effektfunktion 2 als Colour-Variable gewählt: Es ist erkennbar, dass bei geringer sozialer Unterstützung nicht nur die Effektfunktion 1 eher kleinere Werte annimmt (siehe Y-Achse) sondern auch die Effektfunktion 2 eher höhere Werte annimmt (siehe Farbskala). Figure 10.7: Plot 3 - Colour Variable 10.3.3 Regression Line Unter Regression Line kann eingestellt werden, ob eine lineare Funktionsgerade durch die Punkte gelegt werden soll (linear), ob gar keine Funktion dargestellt sondern lediglich die Mittelwerte für die verschiedenen empirisch gefundenen Ausprägungen der X-Achsen-Variable angezeigt werden sollen (none) oder ob eine nicht lineare Funktion mit optimiertem Fit angezeigt werden soll (smooth). Die Option smooth kann von der Option linear abweichen, wenn mehrere Kovariaten (Im Beispiel unten: eine kategoriale und eine kontinuierliche Kovariate) im Regressionsmodell vorhanden sind. Korrelieren die beiden Kovariaten miteinander oder ist das Design unbalanciert, kommt es je nach gewählter Option zu unterschieden in der geschätzten Regressionslinie. In Figure 10.8 wurde die kontinuierliche Kovariate als Regressor eingestellt und smooth als Option gewählt. Figure 10.8: Plot 3 - smoothe Regression Line Dass im Screenshot die Kovariaten miteinander korrelieren, ist daran erkennbar, dass der Zusammenhang der kontinuierlichen Kovariate CPM21 auf die Effektfunktion unter den verschiedenen Bedingungen der kategorialen Kovariate verschieden ist (zwei der „Punktelinien“ verlaufen relativ parallel abwärts, die dritte „Punktelinie“ verläuft fast konstant). 10.3.4 Confidence Intervals Durch einen Klick auf show CIs werden die Konfidenzintervalle der geschätzten Effekte der verschiedenen empirisch gefundenen Ausprägungen der x-Achsen-Variable angezeigt. Durch einen Klick auf Regression CI wird das Konfidenzintervall der Regression selbst als blauer Schatten angezeigt. Wie bereits unter Plot 2 beschrieben, beruht eine solche Schätzung des Konfidenzintervalls auf der Annahme der probabilistischen Testtheorie: Anders als die klassische Testtheorie, die für eine Regression nur einen einzigen Gesamt-Reliabilitäts-Kennwert vorsieht, berücksichtigt die probabilistische Testtheorie, dass eine Regression in Bereichen, in denen viele Beobachtungen von Prädiktor und Regressand vorliegen, zu genaueren Vorhersagen fähig ist, als in Bereichen, in denen nur wenige Beobachtungen vorliegen. 10.3.5 Zusammenhänge zwischen den Graphen des Plot 3 und den Regressionsparametern 10.3.5.1 Kontinuierliche Kovariate Z als Regressor Am häufigsten wird Plot 3 vermutlich für den Zusammenhang einer kontinuierlichen Kovariaten mit einer Effektfunktion erstellt. Betrachten wir als Beispiel hierfür unseren Beispieldatensatz 2, rechnen eine bedingte lineare Regression von Behandlungsart (Treatmentvariable) und subjektiver sozialer Unterstützung (kontinuierliche Kovariate) auf den Gesundheitsscore und stellen als Effektfunktion g1 ein sowie als Regressor subjektive soziale Unterstützung. Figure 10.9: Plot 3 - Beispiel mit kontinuierlicher Kovariate Plot 3 skizziert eine Funktion mit dem Parameter g100 als Y-Achsenabschnitt dem Parameter g101 als Steigung. g100 ist der geschätzte Effekt des Treatments 1 unter der Bedingung \\(\\small Z_1=0\\). g101 schätzt die Interaktion zwischen \\(\\small Z_1\\) und dem Effekt des Teatments 1; g110 schätzt um wie viel der Effekt von Treatment 1 steigt, wenn \\(\\small Z_1\\) um eine Einheit steigt. 10.3.5.2 Kategoriale Kovariate K als Regressor Die Erkenntnisse aus dem letzten Abschnitt (Kontinuierliche Kovariate Z als Regressor) lassen sich auch auf kategoriale Kovariaten übertragen. Rechenen wir im Beispieldatensatz 2 eine Regression von Behandlungsart (Treatmentvariable) und subjektiv ausreichender sozialer Unterstützung (kategoriale Kovariate) auf den Gesundheitsscore (abhängige Variable) und stellen für Plot 3 als Effektfunktion g1 und als Regressor subjektiv ausreichend soziale Unterstützung ein, so erhalten wir folgenden Plot: Figure 10.10: Plot 3 - Beispiel mit kategorialer Kovariate Stellen wir uns eine Regressionsgerade vor, die die beiden Punkte \\(\\small E(g1(K,Z)|K=0)\\) und \\(\\small E(g1(K,Z)|K=1)\\) verbindet, so entspricht auch hier der Parameter g100 aus dem Hauptoutput dem Y-Achsenabschnitt (bzw. dem Punkt E(g1(K,Z)|K=0)). Die „Steigung“ entspricht der Differenz von \\(\\small E(g1(K,Z)|K=1)\\) und \\(\\small E(g1(K,Z)|K=1)\\), und damit dem Parameter g110 aus dem Hauptoutput. 10.4 Plot 4 Plot 4 dient ebenfalls dazu sich einen besseren Überblick über vorliegende Daten zu verschaffen. Man kann sich die einzelnen geschätzten Effekte für alle Fälle des geladenen Datensatzes plotten lassen und sie in Abhängigkeit einer anderen Variable einfärben. Figure 10.11 lässt zum Beispiel darauf schließen, dass höhere Ausprägungen der Kovariaten \\(\\small Z_1\\) mit eher niedrigeren Effekten der g2 Funktion einhergehen (man erkennt ein farbliches Gefälle zwischen oben und unten), die Graphik darunter 10.12 lässt darauf schließen, dass es keinen ausgeprägten Zusammenhang zwischen der Kovariate \\(\\small k1\\) und den Effekten der g2 Funktion gibt. Figure 10.11: Plot 4 - Beispiel 1 Figure 10.12: Plot 4 - Beispiel 2 10.5 Übung “Plots” Lade den Übungsdatensatz 2, rechne eine bedingte lineare Regression mit Gesundheitsscore als Regressand und subjektiver sozialer Unterstützung als Prädiktor. Lasse dir von Plot 3 die Regression des Prädiktors auf eine der Effektfunktionen anzeigen. Wie verändert sich die Steigung der Regressionsgeraden, wenn du anstatt einer bedingten linearen Regression eine zweifache lineare Regression rechnest (im Eingabepanel unter Options No Interactions auswählen)? Mache dir am Vergleich der beiden Graphen klar, worin der Unterschied zwischen den beiden Regressionsmodellen besteht und erkläre, warum sich die Steigung verändert. Die Lösungen und ein Video zur Erklärung findest du hier. "],
["komplex.html", "11 Komplexerer Parametrisierungen - Übungen 11.1 Übungen 11.2 Lösungen", " 11 Komplexerer Parametrisierungen - Übungen In diesem Kapitel werden aufeinander aufbauend Übungen zu immer komplexeren Regressions-Modellen präsentiert. Die Übungen sind theoretischer Natur: Durch komlexere Modelle steigen die Anforderungen an die Interpretation von Parametern und Effekten, die Eingabe der Modelle in EffectLiteR wird hingegen nicht komplizierter. Die Lösungen zu den Aufgaben befinden sich weiter unten im Kapitel. 11.1 Übungen 11.1.1 Übung K1 Gegeben ist folgendes Regressionsmodell mit einer zweistufigen Treatmentvariablen \\(\\small X\\), und einer dreistufigen kategorialen Kovariaten \\(\\small K\\): \\[\\begin{align} E(Y|X,K) &amp;= g0(K) + g1(K) \\times I_{X=1}\\\\ g0(K) &amp;= g000 + g010 \\times I_{K=1} + g020 \\times I_{K=2} \\\\ g1(K) &amp;= g100 + g110 \\times I_{K=1} + g120 \\times I_{K=2} \\end{align}\\] Drücke die Parameter mit Erwartungswerten aus und interpretiere sie in Worten. 11.1.2 Übung K2 Schreibe die Regressionsgleichung / das Regressionsmodell für den Fall einer dreistufigen Treatmentvariable \\(\\small X\\) und einer zweistufigen Treatmentvariable \\(\\small K\\) auf. 11.1.3 Übung K3 Gegeben ist folgendes Regressionsmodell mit einer dreistufigen Treatmentvariablen \\(\\small X\\), und einer dreistufigen kategorialen Kovariaten \\(\\small K\\): \\[\\begin{align} E(Y|X,K) &amp;= g0(K) + g1(K) \\times I_{X=1} + g2(K) \\times I_{X=2}\\\\ g0(K) &amp;= g000 + g010 \\times I_{K=1} + g020 \\times I_{K=2} \\\\ g1(K) &amp;= g100 + g110 \\times I_{K=1} + g120 \\times I_{K=2}\\\\ g2(K) &amp;= g200 + g210 \\times I_{K=1}+ g220 \\times I_{K=2} \\end{align}\\] Drücke die Parameter mit Erwartungswerten aus und interpretiere sie in Worten. 11.1.4 Übung K4 Wenn mehrere kategoriale Variable (z.B. \\(\\small K_1\\) -weiblich vs. männlich- und \\(\\small K_2\\) -Kategorie 2(K1) vs. Kategorie 1(K2)) als Prädiktoren ausgewählt wurden, so kombiniert EffectLiteR diese zu einem gemeinsamen kategorialen Prädiktor. Auf diese Art und Weise kreiert EffectLiteR für das genannte Beispiel eine vierstufige Kovariate K mit den Ausprägungen: K=0 männlich-K1, K=1 männlich-K2, K=2 weiblich-K1, K=3 weiblich-K2 Durch diese Parametrisierung kommt es nicht zur Berechnung von Interaktionen der kategorialen Prädiktoren untereinander. Stelle das entsprechende Regressionsmodell auf und interpretiere seine Parameter inhaltlich (in Worten und Erwartungswerten). 11.1.5 Übung K5 Auch bei mehreren kontinuierlichen Kovariaten wird die Interaktion der Kovariaten nicht zur Aufklärung von Varianz im Prädiktor hinzugezogen. Bei einer zweistufigen Treatmentvariablen und zwei kontinuierlichen Kovariaten wird folgendes Regressionsmodell geschätzt: \\[\\begin{align} E(Y|X,Z_1,Z_2)&amp;= g0(Z_1,Z_2) + g1(Z_1,Z_2) \\times I_{X=1}\\\\ g0(Z_1,Z_2)&amp;= g000 + g001 \\times Z_1 + g002 \\times Z_2\\\\ g1(Z_1,Z_2)&amp;= g100 + g101 \\times Z_1 + g102 \\times Z_2 \\end{align}\\] Angenommen die abhängige Variable steht für einen Gesundheitsscore von Patienten, die Treatmentvariable steht für die Behandlung der Patienten (\\(\\small X=1\\)) vs. keine Behandlung (\\(\\small X=0\\)), die Kovariate \\(\\small Z_1\\) steht für das Alter der Patienten und die Kovariate \\(\\small Z_2\\) für die subjektiv empfundene soziale Unterstützung. Beide Kovariaten wurden z-standardisiert. Drücke die Parameter des Regressionsmodells mit Erwartungswerten aus und interpretiere sie inhaltlich. 11.1.6 Übung K6 Nur wenn sowohl kontinuierliche als auch kategoriale Prädiktoren in das Modell aufgenommen werden, werden Interaktionen zwischen der aggregierten Kategorienvariable \\(\\small K\\) und den verschiedenen kontinuierlichen Variablen geschätzt. In diesem Fall kann unter Interactions im Eingabe-Panel recht genau eingestellt werden, welche Interaktionen geschätzt werden sollen und welche nicht. Generell gilt: Je weniger „unnötige“ Parameter geschätzt werden, desto genauer können die tatsächlich relevanten Parameter geschätzt werden. Deshalb ist sinnvoll nur inhaltlich plausible Interaktionen in seinem Modell zu belassen. In der Abbildung unten (Figure 11.1) siehst du ein Modell mit zwei kontinuierlichen und einer kategorialen Kovariaten, außerdem die möglichen Einstellungen zur Begrenzung des Modells unter Interactions im Eingabepanel. Überlege welche Parameter unter den verschiedenen möglichen Restriktionen nicht geschätzt würden (Welche Parameter würden unter der Einstellung Only two way interactions nicht geschätzt, welche unter der Einstellung only X:K and X:Z interactions,…). Figure 11.1: Übung komplexes Modell 6.png 11.2 Lösungen Bemerke: Für Übung K1 ist ein detaillierter Lösungsweg abgebildet, während für die verwandten Übungen K3-K5 ledigliche die Ergebnisse vorliegen. Gehe zur Lösung der Übungen K3-K5 genau so vor, wie zur Lösung der Aufgabe K1. 11.2.1 Lösung K1 Schritt1) X und K auf null setzen: \\[\\begin{align} E(Y|X=0,K=0) &amp;= g_{000} + g_{010} \\times 0+ g_{020} \\times 0+ (g_{100} + g_{110} \\times 0 + g_{120} \\times 0) \\times 0\\\\ &amp;= g_{000} \\end{align}\\] g000 gibt den Erwartungswert unter der Bedingung X=0, K=0 an. Schritt 2) X auf null und K auf eins setzen, dann Erwartungswert für g000 einsetzen: \\[\\begin{align} E(Y|X=0,K=1) &amp;= g_{000} + g_{010} \\times 1+ g_{020} \\times 0+ (g_{100} + g_{110} \\times 1 + g_{120} \\times 0) \\times 0\\\\ &amp;= g_{000} + g_{010}\\\\ &amp;= E(Y|X=0,K=0) + g_{010}\\\\ g_{010} &amp;=E(Y|X=0,K=1)-E(Y|X=0,K=0) \\end{align}\\] g010 gibt den Effekt einer Veränderung der Kovariaten von 0 zu 1 unter der Bedingung X=0 an. Schritt 3) X auf null und K auf zwei setzen, dann Erwartungswert für g000 einsetzen: \\[\\begin{align} E(Y|X=0,K=2) &amp;= g_{000} + g_{010} \\times 0+ g_{020} \\times 1+ (g_{100} + g_{110} \\times 0 + g_{120} \\times 1) \\times 0\\\\ &amp;= g_{000} + g_{020}\\\\ &amp;= E(Y|X=0,K=0) + g_{020}\\\\ g_{020} &amp;=E(Y|X=0,K=2)-E(Y|X=0,K=0) \\end{align}\\] g020 gibt den Effekt einer Veränderung der Kovariaten von 0 zu 1 unter der Bedingung X=0 an. Schritt 4) X auf eins und K auf null setzen, dann Erwartungswert für g000 einsetzen: \\[\\begin{align} E(Y|X=1,K=0) &amp;= g_{000} + g_{010} \\times 0+ g_{020} \\times 0+ (g_{100} + g_{110} \\times 0 + g_{120} \\times 0) \\times 1\\\\ &amp;= g000 + g100\\\\ &amp;= E(Y|X=0,K=0) + g_{100}\\\\ g_{100} &amp;=E(Y|X=1,K=0)-E(Y|X=0,K=0) \\end{align}\\] g100 gibt den Effekt des Treatments (X=1 vs X=0) unter der Bedingung K=0 an. Schritt 5) X auf eins und K auf eins setzen, dann Erwartungswerte für g000, g010 und g100 einsetzen, dann kürzen: \\[\\begin{align} E(Y|X=1,K=1) &amp;= g_{000} + g_{010} \\times 1+ g_{020} \\times 0+ (g_{100} + g_{110} \\times 1 + g_{120} \\times 0) \\times 1\\\\ &amp;= g_{000} + g_{010} + g_{100} + g_{110}\\\\ &amp;= E(Y|X=0,K=0) + [E(Y|X=0,K=1)-E(Y|X=0,K=0)] +\\\\ &amp;+[E(Y|X=1,K=0)-E(Y|X=0,K=0)] + g_{110} \\\\ &amp;=E(Y|X=0,K=1) + [E(Y|X=1,K=0)-E(Y|X=0,K=0)] + g_{110}\\\\ g_{110}&amp;=[E(Y|X=1,K=1) - [E(Y|X=0,K=1)] – \\\\ &amp;-[E(Y|X=1,K=0)-E(Y|X=0,K=0)] \\end{align}\\] g110 ist die Differnz des Treatmenteffektes unter der Bedingung K=1 und unter der Bedingung K=0, damit stellt er die Interaktion zwischen X und K=1 versus K=0 dar. Schritt 6) X auf eins und K auf zwei setzen, dann Erwartungswerte für g000, g010 und g100 einsetzen, dann kürzen: \\[\\begin{align} E(Y|X=2,K=1) &amp;= g_{000} + g_{010} \\times 0+ g_{020} \\times 1+ (g_{100} + g_{110} \\times 0 + g_{120} \\times 1) \\times 1\\\\ &amp;= g_{000} + g_{020} + g_{110} + g_{120}\\\\ &amp;= E(Y|X=0,K=0) + [E(Y|X=0,K=2)-E(Y|X=0,K=0)] +\\\\ &amp;+[E(Y|X=1,K=0)-E(Y|X=0,K=0)] + g_{120} \\\\ &amp;=E(Y|X=0,K=2) + [E(Y|X=1,K=0)-E(Y|X=0,K=0)] + g_{120}\\\\ g_{120}&amp;=[E(Y|X=1,K=2) - [E(Y|X=0,K=2)] –\\\\ &amp;-[E(Y|X=1,K=0)-E(Y|X=0,K=0)] \\end{align}\\] g120 ist die Differnz des Treatmenteffektes von X unter der Bedingung K=2 und unter der Bedingung K=0, damit stellt er die Interaktion zwischen X und K=2 versus K=0 dar. 11.2.2 Lösung K2 \\[\\begin{align} E(Y|X,K) &amp;= g0(K) + g1(K) \\times I_{X=1}\\\\ g0(K) &amp;= g_{000} + g_{010} \\times I_{K=1} \\\\ g1(K) &amp;= g_{100} + g_{110} \\times I_{K=1} \\\\ g2(K) &amp;= g_{200} + g_{210} \\times I_{K=1} \\end{align}\\] 11.2.3 Lösung K3 Ewartungswert Interpreation in Worten \\(\\small g_{000}=E(Y|X=0,K=0)\\) g000 gibt den Erwartungswert unter der Bedingung X=0, K=0 an. \\(\\small g_{010} =E(Y|X=0,K=1)-E(Y|X=0,K=0)\\) g010 gibt den Effekt einer Veränderung der Kovariaten von 0 zu 1 unter der Bedingung X=0 an. \\(\\small g_{020} =E(Y|X=0,K=2)-E(Y|X=0,K=0)\\) g020 gibt den Effekt einer Veränderung der Kovariaten von 0 zu 2 unter der Bedingung X=0 an \\(\\small g_{100} =E(Y|X=1,K=0)-E(Y|X=0,K=0)\\) g100 gibt den Effekt des Treatments (X=1 vs X=0) unter der Bedingung K=0 an. \\(\\small g_{110}=[E(Y|X=1,K=1) - [E(Y|X=0,K=1)]-\\\\ \\small – [E(Y|X=1,K=0)-E(Y|X=0,K=0)]\\) g110 ist die Differnz des Treatmenteffektes unter der Bedingung K=1 und unter der Bedingung K=0, damit stellt er die Interaktion zwischen X und K=1 versus K=0 dar. \\(\\small g_{120} =[E(Y|X=1,K=2) - [E(Y|X=0,K=2)] –\\\\ \\small-[E(Y|X=1,K=0)-E(Y|X=0,K=0)]\\) g120 ist die Differnz des Treatmenteffektes von X unter der Bedingung K=2 und unter der Bedingung K=0, damit stellt er die Interaktion zwischen X und K=2 versus K=0 dar. \\(\\small g_{200} =E(Y|X=2,K=0)-E(Y|X=0,K=0)\\) g200 gibt den Effekt des Treatments (X=2 vs X=0) unter der Bedingung K=0 an. \\(\\small g_{210} =[E(Y|X=2,K=1) - [E(Y|X=0,K=1)] –\\\\ \\small-[E(Y|X=2,K=0)-E(Y|X=0,K=0)]\\) g210 ist die Differnz des Treatmenteffektes (X=2 vs X=0) unter der Bedingung K=1 und unter der Bedingung K=0, damit stellt er die Interaktion zwischen X=2 vs X=0 und K=1 versus K=0 dar. \\(\\small g220=[E(Y|X=2,K=2) - [E(Y|X=0,K=2)] –\\\\ \\small -[E(Y|X=2,K=0)-E(Y|X=0,K=0)]\\) g220 ist die Differnz des Treatmenteffektes von X (X=2 vs X=0) unter der Bedingung K=2 und unter der Bedingung K=0, damit stellt er die Interaktion zwischen X=2 vs X=0 und K=2 versus K=0 dar. 11.2.4 Lösung K4 Regressionsmodell: \\[\\begin{align} E(Y|X,K) &amp;= g0(K) + g1(K) \\times I_{X=1}\\\\ g0(K)&amp;=g_{000} + g_{010} \\times I_{K=1} + g_{020} \\times I_{K=2} + g_{030} \\times I_{K=3} \\\\ g1(K)&amp;=g_{100} + g_{110} \\times I_{K=1} + g_{120} \\times I_{K=2} + g_{130} \\times I_{K=3} \\end{align}\\] Ewartungswert Interpreation in Worten \\(\\small g_{000} = E(Y|X=0,K=0)\\) g000 gibt den Erwartungswert unter der Bedingung X=0 für Männer der Kategorie 1 an. \\(\\small g_{010} = E(Y|X=0,K=1)-E(Y|X=0,K=0)\\) g010 gibt den Effekt der Kovariatenausprägung K=1 vs K=0 unter der Bedingung X=0 an: Um wie viel steigert sich der Erwartungswert von Y, wenn statt Männern der Kategorie eins (K=0) Frauen der Kategorie eins (K=1) betrachtet werden. \\(\\small g_{020} = E(Y|X=0,K=2)-E(Y|X=0,K=0)\\) g020 gibt den Effekt der Kovariatenausprägung K=2 vs K=0 unter der Bedingung X=0 an: Um wie viel steigert sich der Erwartungswert von Y, wenn statt Männern der Kategorie eins (K=0) Männer der Kategorie zwei (K=2) betrachtet werden. \\(\\small g_{030} = E(Y|X=0,K=3)-E(Y|X=0,K=0)\\) g030 gibt den Effekt der Kovariatenausprägung K=3 vs K=0 unter der Bedingung X=0 an: Um wie viel steigert sich der Erwartungswert von Y, wenn statt Männern der Kategorie eins (K=0) Frauen der Kategorie zwei (K=3) betrachtet werden. \\(\\small g_{100} = E(Y|X=1,K=0)-E(Y|X=0,K=0)\\) g100 gibt den Treatmenteffekt für Männer der Kategorie 1 an. \\(\\small g_{110}=[E(Y|X=1,K=1) - E(Y|X=0,K=1)] –\\\\ \\small - [E(Y|X=1,K=0)-E(Y|X=0,K=0)]\\) g110 gibt die Interaktion zwischen der Betrachtung von Männern der Kategorie zwei (K=0) vs. der Betrachtung von Frauen der Kategorie eins (K=1) und dem Treatment an: Um wie viel effektiver ist das Treatment bei Frauen der Kategorie 1 (K=1) als bei Männern der Kategorie 1 (K=0). \\(\\small g_{120}=[E(Y|X=1,K=2) - E(Y|X=0,K=2)] –\\\\ \\small - [E(Y|X=1,K=0)-E(Y|X=0,K=0)]\\) g120 gibt die Interaktion zwischen der Betrachtung von Männern der Kategorie zwei (K=2) vs. der Betrachtung von Männern der Kategorie eins (K=1) und dem Treatment an: Um wie viel effektiver ist das Treatment bei Männern der Kategorie 2 (K=2) als bei Männern der Kategorie 1 (K=0). \\(\\small g_{130}=[E(Y|X=1,K=3) - E(Y|X=0,K=3)] –\\\\ \\small - [E(Y|X=1,K=0)-E(Y|X=0,K=0)]\\) g130 gibt die Interaktion zwischen der Betrachtung von Frauen der Kategorie zwei (K=3) vs. der Betrachtung von Männern der Kategorie eins (K=0) und dem Treatment an: Um wie viel effektiver ist das Treatment bei Frauen der Kategorie 2 (K=3) als bei Männern der Kategorie 1 (K=0). Bemerke: Hier bestimmt die Kodierung der Kovariate, welche Vergleiche geschätzt werden: K=0 ist die „Referenz-Kovariaten-Ausprägung“, ein Vergleich der Kovariaten-Ausprägungen K=1 vs K=2 wird beispielsweise nicht geschätzt. Es ist nicht möglich die „Referenz-Kovariaten-Ausprägung“ zu verändern, hier muss also von Anfang an mit einer sinnvollen Kodierung gestartet werden. 11.2.5 Lösung K5 Ewartungswert Interpreation in Worten \\(\\small g000 = E(Y|X=0, Z_1=\\bar{z}_1=0, Z_2=\\bar{z}_2=0)\\) g000 zeigt den erwarteten Gesundheitsscore von Patienten in durchschnittlichem Alter mit durchschnittlich ausgeprägter sozialer Unterstützung, die keine Behandlung erhalten, an. \\(\\small g001 = E(Y|X=0, Z_1=\\bar{z}_1+1\\times SD_{Z1}=1, Z_2=\\bar{z}_2=0)-\\\\ \\small -E(Y|X=0, Z_1=\\bar{z}_1=0, Z_2=\\bar{z}_2=0)\\) g010 schätzt den Einfluss der Kovariaten \\(Z_1\\) in der Kontrollgruppe: Wie viel größer ist der Gesundheitsscore von Patienten ohne Behandlung, die eine Standardabweichung älter sind als das Mittel, im Vergleich zu durchschnittlich alten Patienten ohne Behandlung. \\(\\small g002 = E(Y|X=0, Z_1=\\bar{z}_1=0, Z_2=\\bar{z}_2+1\\times SD_{Z1}=1)-\\\\ \\small -E(Y|X=0, Z_1=\\bar{z}_1=0, Z_2=\\bar{z}_2=0)\\) g002 schätzt den Einfluss der Kovariaten \\(Z_2\\) in der Kontrollgruppe: Wie viel größer ist der Gesundheitsscore von Patienten ohne Behandlung, die subjektiv bewertet um eine Standardabweichung höhere soziale Unterstützung erfahren als das Mittel, im Vergleich zu Patienten mit subjektiv gemessen durchschnittlicher sozialer Unterstützung ohne Behandlung. \\(\\small g100 = E(Y|X=1, Z_1=\\bar{z}_1=0, Z_2=\\bar{z}_2=0)-\\\\ \\small -E(Y|X=0, Z_1=\\bar{z}_1=0, Z_2=\\bar{z}_2=0)\\) g100 gibt den durchschnittlichen Treatmenteffekt an, das heißt die geschätzte Differenz zwischen durchschnittlich alten und subjektiv durchschnittlich sozial unterstützten Patienten mit und ohne Behandlung. \\(\\small g101=[E(Y|X=1,Z_1=\\bar{z}_1+1\\times SD_{Z1}=1, Z_2=\\bar{z}_2=0) -\\\\ \\small -E(Y|X=0,Z_1=\\bar{z}_1+1\\times SD_{Z1}=1, Z_2=\\bar{z}_2=0)] –\\\\ \\small [E(Y|X=1,Z_1=\\bar{z}_1=0, Z_2=\\bar{z}_2=0)-\\\\ \\small -E(Y|X=0,Z_1=\\bar{z}_1=0, Z_2=\\bar{z}_2=0)]\\) g101 schätzt den Einfluss der Interaktion zwischen Treatment und Alter auf den Gesundheitsscore: Wie viel größer ist der Effekt des Treatments bei Patienten die eine Standardabweichung älter sind als der Durchschnitt, als bei durchschnittlich alten Patienten. \\(\\small g102=[E(Y|X=1,Z_1=\\bar{z}_1=0, Z_2=\\bar{z}_2+1\\times SD_{Z2}=1) -\\\\ \\small -E(Y|X=0,Z_1=\\bar{z}_1=0, Z_2=\\bar{z}_2+1\\times SD_{Z2}=1)] –\\\\ \\small -[E(Y|X=1,Z_1=\\bar{z}_1=0, Z_2=\\bar{z}_2=0)-\\\\ \\small -E(Y|X=0,Z_1=\\bar{z}_1=0, Z_2=\\bar{z}_2=0)]\\) g102 schätzt den Einfluss der Interaktion zwischen Treatment und subjektiver sozialer Unterstützung auf den Gesundheitsscore: Wie viel größer ist der Effekt des Treatments bei Patienten die subjektiv gemessen eine Standardabweichung höhere soziale Unterstützung erfahren als der Durchschnitt, als bei subjektiv durchschnittlich sozial unterstützten Patienten. 11.2.6 Lösung K6 Restriktion auf Null fixierte Parameter Only two-way interactions g111, g112,g211, g212 Only X:K and X:Z interactions g011, g012,g111, g112,g211, g212 Only X:K interactions g101, g102, g111, g112,g201, g202, g211, g212 Only X:Z interactions g110, g111, g112,g210, g211, g212, No treatment*covariate interactions g101, g102, g110, g111, g112,g201, g202, g210, g211, g212 No interactions g011, g012,g101, g102, g110, g111, g112,g201, g202, g210, g211, g212 "],
["übungen-1.html", "12 Übungen 12.1 Dateneinlesen 12.2 Einfache lineare Regression 12.3 Zweifache lineare Regression 12.4 Bedingte lineare Regression 12.5 Plots", " 12 Übungen 12.1 Dateneinlesen Downloade den Übungsdatensatz 1 und lese ihn mit EffectLiteR ein. Der Datensatz entspricht nicht den Default-Einstellungen von EffectLiteR, du musst Änderungen an den Additional Options to Read Data vornehmen, insgesamt sind drei Änderungen notwendig, bevor du anfangen könntest Berechnungen am Datensatz vorzunehmen. Führe diese drei Änderungen durch, gehe Schrittweise vor und achte dabei auf Plausibilität der angezeigten Daten. 12.2 Einfache lineare Regression Der Übungsdatensatz 2 enthält (unter anderem) simulierte Daten für das Beispiel 2. Lese den Datensatz ein und wähle Gesundheitsscore als abhängige Variable und Behandlungsart als Treatmentvariable. 12.2.1 A) Interpretiere den Hauptoutput: Wie groß sind die jeweiligen Erwartungswerte des Gesundheitsscores unter den drei verschiedenen Behandlungsarten? Wie groß sind die deskriptiven Unterschiede zwischen den verschiedenen Bedingungen (keine Behandlung, Behandlung 1, Behandlung 2)? Unterscheiden sich alle drei Bedingungen signifikant von einander? Beachte: Um den Unterschied zwischen Behandlung 1 und Behandlung 2 zu interpretieren muss die Referenzgruppe verändert werden. 12.2.2 B) Errechne die Standardabweichung der abhängigen Variable Gesundheitsscore im Übungsdatensatz 2 für Personen, die keine Behandlung erhielten, mithilfe der Effektstärke aus dem EffectLiteR-Output. Wie das geht kannst du unter Average Effects nachlesen. 12.3 Zweifache lineare Regression 12.3.1 A) Der Übungsdatensatz 2 enthält (unteranderem) simulierte Daten für das Beispiel 3. Lese den Datensatz ein, wähle Gesundheitsscore als abhängige Variable, Behandlungsart als Treatmentvariable und subjektiv ausreichend soziale Unterstützung als kategoriale Kovariate. Interpretiere den Hauptoutput: Wie groß ist der Erwartete Gesundheitsscore unter folgenden Bedingungen: Behandlungsart = 0, subj_ausreichend_soz_Unterstützung = 0 Behandlungsart = 0, subj_ausreichend_soz_Unterstützung = 1 Behandlungsart = 1, subj_ausreichend_soz_Unterstützung = 0 Behandlungsart = 1, subj_ausreichend_soz_Unterstützung = 1 Behandlungsart = 2, subj_ausreichend_soz_Unterstützung = 0 Behandlungsart = 2, subj_ausreichend_soz_Unterstützung = 1 Wie groß ist der Effekt von Behandlungsart 1 im Vergleich zu Behandlungsart 0 und ist er signifikant? Wie groß ist der Effekt von Behandlungsart 2 im Vergleich zu Behandlungsart 0 und ist er signifikant? Wie groß ist der Effekt von subjektiv ausreichender sozialer Unterstützung und ist er signifikant? 12.3.2 B) Nutze nun subjektive soziale Unterstützung als kontinuierliche Kovariate, ansonsten belasse alle Variablen wie in Teil A) der Übung. Die verwendeten Variablen entsprechen nun Beispiel 4. Berechne eine bedingte Regression von Behandlungsart und subjektiv gemessener sozialer Unterstützung (kontinuierlich) auf den Gesundheitsscore (entspricht Beispiel 4. Beachte: Zur Lösung der Aufgabe ist es hilfreich, wenn die kontinuierliche Kovariate z-standardisiert ist. Die z-Standardisierung muss vor dem Einlesen in EffectLiteR erfolgen. Interpretiere den Hauptoutput: Wie groß ist der erwartete Gesundheitsscore unter den verschiedenen Ausprägungen von X a) bei durchschnittlicher Ausprägung der Kovariate und b) bei einer Kovariaten-Ausprägung von einer Standardabweichung über dem Durchschnitt. Wie groß ist der Effekt von Behandlungsart 1 im Vergleich zu Behandlungsart 0 und ist er signifikant? Wie groß ist der Effekt von Behandlungsart 2 im Vergleich zu Behandlungsart 0 und ist er signifikant? Hat subjektive soziale Unterstützung einen signifikanten Einfluss auf den Gesundheitsscore? Welchen Effekt hat die Steigerung von subjektiver sozialer Unterstützung um anderthalb Standardabweichung auf den Gesundheitsscore? 12.4 Bedingte lineare Regression Rechne eine bedingte lineare Regression mit Gesundheitsscore als abhängiger Variable, Behandlungsart als Treatmentvariable und subjektiver sozialer Unterstützung als kategoriale Kovariate (Daten aus dem Übungsdatensatz 2). Beachte: Die inhaltliche Interpretation der Parameter wird durch z-Standardisierung der kontinuierlichen Kovariaten deutlich erleichtert, die Transformation der Daten muss vor dem Einlesen in EffectLiteR geschehen. 12.4.1 A) Wird der Interaktionseffekt signifikant? Interpretiere die Aussage des Interaktionseffektes in Worten. Rechne mit dem selben Datensatz zusätzlich eine zweifache lineare Regression (d.h. deaktiviere Interaktionseffekte unter Options). Vergleiche Die Parameter g000, g001, g100 und g200 die in beiden Fällen geschätzt werden, was fällt dir auf? Welche Parameter erscheinen dir vertrauenserweckender, d.h. welche Effekte würdest du interpretieren und warum? 12.4.2 B) Ein Patient hat die Kovariatenausprägung \\(\\small z_1=8\\) (nach z-Standardisierung: \\(\\small z&#39;_1\\approx 1.784\\)) und wurde mit Behandlungsmethode 1 behandelt. Welcher Gesundheitsscore kann bei ihm erwartet werden? (Zur Beantwortung dieser Frage ist das Kapitel Conditional Effects hilfreich. Ein anderer Patient hat ebenfalls eine Kovariatenausprägung von z=8 (z’=xy), wurde aber noch nicht behandelt. Welche Behandlungsart würde ihm, basierend auf den vorliegenden Daten, vermutlich am besten helfen? (Zur Beantwortung dieser Frage ist das Kapitel Conditional Effects hilfreich. 12.5 Plots Lade den Übungsdatensatz 2, rechne eine bedingte lineare Regression mit Gesundheitsscore als Regressand und der Behandlungsart subjektiver sozialer Unterstützung als Prädiktor. Lasse dir von Plot 3 die Regression subjektiver sozialer Unterstützung auf eine der Effektfunktionen anzeigen. Wie verändert sich die Steigung der Regressionsgeraden, wenn du anstatt einer bedingten linearen Regression eine zweifache lineare Regression rechnest (im Eingabepanel unter Options No Interactions auswählen)? Mache dir am Vergleich der beiden Graphen klar, worin der Unterschied zwischen den beiden Regressionsmodellen besteht und erkläre, warum sich die Steigung verändert. Weitere Aufgaben finden sich im Kapitel Komplexerer Parametrisierungen - Übungen "],
["lösungen.html", "13 Lösungen 13.1 Dateneinlesen 13.2 Einfache lineare Regression 13.3 Zweifache lineare Regression 13.4 Bedingte lineare Regression 13.5 Plots", " 13 Lösungen 13.1 Dateneinlesen Folgende Einstellungen müssen unter Additional Options to Read Data vorgenommen werden: Figure 13.1: Nötige Veränderungen unter Additionl Options to Read Data Siehe die Lösung im Video an: 13.2 Einfache lineare Regression 13.2.1 A) Erwartungswerte unter den verschiedenen Behandlungsarten: \\(\\small E(Y|X=0)=30.5\\) \\(\\small E(Y|X=1)=45.9\\) \\(\\small E(Y|X=2)=52.3\\) Unterschiede zwischen den Behandlungsarten: \\(\\small E(Y|X=1)\\) vs. \\(\\small E(Y|X=0)\\) entspricht g100: 15.36 \\(\\small E(Y|X=2)\\) vs. \\(\\small E(Y|X=0)\\) entspricht g200: 21.78 \\(\\small E(Y|X=2)\\) vs. \\(\\small E(Y|X=1)\\) entspricht g200 nach Wechsel der Referenzgruppe: 6.42 Siehe die Lösung im Video an: 13.2.2 B) Unter Average Effects im Hauptoutput finden sich die absoluten und die (an der Standardabweichung der AV in der Kontrollgruppe) standardisierten durchschnittlichen Effekte. \\(\\small Effect Size = \\frac{Estimate}{SD_{YinKontrollgruppe}}\\) \\(\\small 1.63 \\approx \\frac{15.4}{9.44}\\) oder \\(\\small 2.31 \\approx \\frac{21.8}{9.44}\\) Daraus Folgt: \\(\\small SD_{YinKontrollgruppe} \\approx 9.44\\) 13.3 Zweifache lineare Regression 13.3.1 A) Bedingte Erwartungswerte: \\(\\small E(Y|X=0,K=0)=29.228\\) \\(\\small E(Y|X=0,K=1)=32.3\\) \\(\\small E(Y|X=1,K=0)=44.608\\) \\(\\small E(Y|X=1,K=1)=47.679\\) \\(\\small E(Y|X=2,K=0)=51.102\\) \\(\\small E(Y|X=2,K=1)=54.173\\) Effekt von Behandlungsart 1 im Vergleich zu Behandlungsart 0: \\(\\small g_{100}=15.38\\), \\(\\small p&lt;0.05\\) Effekt von Behandlungsart 2 im Vergleich zu Behandlungsart 0: \\(\\small g_{200}=21.874\\), \\(\\small p&lt;0.05\\) Effekt der Kovariaten: \\(\\small g_{010}=3.072\\), \\(\\small p&lt;0.05\\) Siehe die Lösung im Video an: 13.3.2 B) Subjektive soziale Unterstützung z-standardisieren: \\(\\small X_{z-stand.}=\\frac{X-\\bar{X}}{SD_X}\\) Wie du eine Variable z-standardisierst kannst dir auch in folgenden Videos ansehen: Detaillierte Erläuterung zur z-Standardisierung von Variablen mit R: Video zur z-Standardisierung von Variablen mit Excel: Ansonsten ist die Aufgabe äquivalent zu lösen wie Aufgabe 1 zur zweifachen linearen Regression. Achte darauf, die z-standardisierte Variable unter Continuous Covariates Z einzugeben und unter Interactions No interactions auszuwählen. Bedingte Erwartungswerte: $E(Y|X=0,Z_1={Z_1}=0)=30.673 $ $E(Y|X=0,Z_1={Z_1}+SD_{Z_1}=1)=33.582 $ $E(Y|X=1,Z_1={Z_1}=0)=45.531 $ $E(Y|X=1,Z_1={Z_1}+SD_{Z_1}=1)=48.441 $ \\(\\small E(Y|X=2,Z_1=\\bar{Z_1}=0)=52.556\\) \\(\\small E(Y|X=2,Z_1=\\bar{Z_1}+SD_{Z_1}=1)=55.466\\) Der Effekt von Behandlungsart 1 im Vergleich zu Behandlungsart 0: \\(\\small g_{100}=14.859\\), signifikant da \\(\\small p&lt;0.05\\) Der Effekt von Behandlungsart 2 im Vergleich zu Behandlungsart 0: \\(\\small g_{200}=21.884\\), signifikant da \\(\\small p&lt;0.05\\) Der Effekt einer Änderung der Kovariaten um plus 1,5 Standardabweichungen berechnet sich durch \\(\\small g_{001}\\times 1.5=4,3635\\) (Aufgrund der z-Standardisierung der Kovariate entspricht g001 dem Effekt der Steigerung um eine Standardabweichung). Der Effekt ist signifikant, da \\(\\small p_{g_{001}}&lt;0.05\\) 13.4 Bedingte lineare Regression 13.4.1 A) Es gibt eine signifikante Interaktion, der Parameter g101 wird signifikant, der Parameter g201 wird allerdings nicht signifikant. Dies bedeutet: Bei Behandlungsart 1 hat die Kovariaten Ausprägung einen Effekt auf den Gesundheitsscore, der über den Effekt der Kovariate in der Kontrollgruppe hinausgeht, der Effekt der Kovariaten bei Behandlungsart 2 weicht nicht signifikant vom Effekt der Kovariaten in der Kontrollbedingung ab. Ein Patient, der mit Behandlungsart 1 behandelt wird und eine Kovariaten ausprägung von \\(\\small z_1 = \\bar{Z_1}+SD_{Z1}\\) hat, hat geschätzt einen um \\(\\small g_{001}+g_{101}=4.789\\) Punkte höheren Gesundheitsscore, als ein Patient mit durchschnittlicher Kovariaten-Ausprägung, der mit der selben Behandlungsmethode behandelt wurde. Der Intercept-Parameter g000 ist in beiden Fällen identisch, die Parameter, die die Effekte von Treatment und/oder Kovariate abbilden verändern sich aber abhängig davon, ob eine Interaktion zwischen Treatment und Kovariate geschätzt wird. Da eine Interaktion vorliegt (die Kovariate hat unter Behandlungsart 1 größere Auswirkungen auf den Gesundheitsscore als in der Kontrollgruppe), macht die zweifache lineare Regression falsche Annahmen, ihre Parameter sind dementsprechend weniger Vertrauenswürdig als die der bedingten linearen Regression. Siehe die Lösung im Video an: 13.4.2 B) \\(\\small E(Y|X=1,Z&#39;_1=1.784)=53.837\\) \\(\\small E(Y|X=0,Z&#39;_1=1.784)=34.455 &lt; E(Y|X=1,Z&#39;_1=1.784)=53.837 &lt;l E(Y|X=2,Z&#39;_1=1.784)=55.273\\): Wir würden dem Patienten Behandlungsart 2 empfehlen, da diese den höchsten Erwartungswert erwarten lässt. Siehe die Lösung im Video an: 13.5 Plots Die bedingte lineare Regression erlaubt einen linearen Einfluss der Kovariaten auf die Effektfunktion: Behandlungsart 1 wirkt um so stärker, je höher die Ausprägung der Kovariaten bei behandelten Patienten ist. Die zweifache lineare Regression erlaubt lediglich einen konstanten Einfluss der Kovariaten auf die Behandlungsart. Die Effektfunktion verändert sich nicht in Abhängigkeit der Kovariaten-Ausprägung, sondern wird für alle Patienten gleich geschätzt. Höre dir die Erklärung im Video an: "]
]
